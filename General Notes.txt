

Block Labelling
- The 3 digit NGI numbers like "320" I think are job numbers.
  They dont relate to the 4 digit (like 3320) numbers
- The 4 digit numbers eg 3320 are std labelling for topographical maps
- The block 3321 is divided into 4 sub blocks 3321A-D.  
  These are the dir names in NGI's "Calibrated" directory.
  One of these A/B/C/D blocks is the same size as a job (3 digit label)
- Each sub-block is further divided into 4 eg AA,AB,AC,AD.  
  Lets call it a subsub-block
- One sub-block of raw data is about 152GB (RGB+CIR) of unrectified data (12 bit)
  There are 42 subsub-blocks in the Little Karoo, therefore 10.5 sub-blocks
- We need 1596 GB of space for all the images
- We need at least double that to store the rectified product, so 4TB
- Note that the rectified images are smaller (8 bit) although in storage they are ~10x smaller ??? JPEG compression!
- Also remember that the unrectified images overlap by a substantial ammount

ArcMap
- The rendering of the 16bit tiffs from NGI is A LOT faster than the rendering of the 12bit orthorectified pix files generated by PCI


NGI
- How is aero-tri better than GPS/INS
- What format is aero-tri?  What sw do they use for ortho-rectification
- Calib cert's
- I am missing 3321C from rectified RGB (looking at NGI docs, apparently it was flown but not rectified)

SU (Garth)
- I need blocks 3320-3323 for DEM
- MS Office
- Erdas Imagine
- DEM with 8 bit depth - res problems??
- Some SUDEM blocks seem blank

To Do
-DEM from image
-Understand orth proc & GPS/INS
-Play with ArcMap
-Fiducial defn?
-Aero-tri vs gps/ins

Notes
ArcMap
------
- ArcMap: To add existing basemap as opposed to basemap layer placeholder, use file->data->add basemap
- ArcMap: double click on toolbar to add other toolbars (or right click)
- PCI: To get the +21 x degrees, I changed the Transverse Mercator longitude origin to 21 deg.  This roughly worked but I'm not sure that its right.
- ArcMap does not like hard drives being turned on and off so make sure you use "always on" power or restart ArcMap.
- There are raster datasets, catalogs and mosaics.  A dataset is the most basic and is pretty much just the raw image data.  A catalog is a collection
of datasets.  A mosaic is also a collection of datasets but is a more recent innovation.  You can have spatial and temporal mosaics.  They are displayed
"seamlessly" and managed / operated on as one entity.  (I think "operated on" is nb as you can only operate on one dataset at a time)
- To make a raster mosaic:
  - Use catalog to make a file database
  - Right click db->New->Mosaic... (container)
  - Right click Mosaic->Add Rasters 
  - You can specify a root folder in the dialog input section, just type/copy it in and chack Advanced Options->Include Subfolders
  - Make sure "Update Overviews" is checked (this includes the pyramids)
  - DONT run windows explorer before/during - seems to create an issue with 10.1 possibly due to thumbnail creation
  - NB Use the add workspace and not dataset option to add folders.  Adding multiple files has some bug in 10.1
  - Selecting the folder in "add workspace" on SunGis08 v10.1 is a problem.  It seems to work if I change to "file" and type in the path then click"+".
- Overview files are ~ to pyramids
- File->Export Map to export current view as image
- Each layer can have its own co-ord sys (geographic or projected).  These are transformed into a common space (that of the data frame).
If a layer's spatial ref is undefined, it will inherit that of the data frame.  Units are defined separately from co-ord sys (in data frame props).
- When adding xy data, you define the spatial ref in the addition dialog.
- Sometimes layer have defined extent info but undefined spatial ref (eg mosaic.tif) in the tutorial.  Then you need to define the data frame's
spatial ref to be the right for that layer so it inherits correctly.  I'm not sure how to change the spatial ref of a particular layer.
- You can set the spatial reference with ArcCatalog
- 12 bit NGI images have 16bit channels and thus aren't rendered properly. They must be min-max rendered with max = 4096
 - BEWARE: ArcMap defaults to a statistical Min-Max stretch rather than an actual BitsPerSample stretch when "Stretch Type" is set to none
 This can create all kinds of confusion when comparing different mosaics, individual images etc.  You must set it to custom with 0-4096 limits!!!
- When specifying the display extent for eg a mosaic, it must be in the projection co-ords of that layer (i.e. the options of specifying the extent of other layers doesn't work if those layers are not the same co-ords). Actually there is a bug here, the only way to change the display extent is by manually entering vals

- Mosaic color correction
 - Using a tgt reference image with eg "histogram matching" just uses the entire tgt image to find a tgt histogram.  The spatial location
  of the tgt image is irrelevant.  
 - The tgt image does seem to have relevance for dodging option where first order gives convincing results (not for CIR!).
  I would guess it is fitting a plane through the colour of the MODIS image and doing a white balance per image on the mosiac to achieve a similar
  plane for the mosaic but on an average colour per image basis.  CIR looks awful though.
 - The matching options which use overlapping regions are not working well because of the black regions in the rectified images which are not being 
  ignored.  Also the ordering of this match seems to be only between subsequent images in the file list rather than all spatially neighbouring
  images which means their are still vertical colour differences between rows.  
 - When I set the nodata properly, the matching options no longer produce the bad effects noted above.  The mosaic does look smoother for the 
  most part but there are still some suspect tiles and I still think the matching is happening sequentially rather than spatially.
 - Dodging balancing looks the most convincing but is theoretically suspect
 - The balancing options that work for the catalog seemingly do nothing for the mosaic... 

- Polygons:
  - To do a reasonable smoothing of a walked Trimble polygon, use Cartography Tools->Generalization->Smooth Line with a smoothing tolerance of 2e-4m
  - When converting a line to a polygon, the line must overlap/instersect itself, then the polygon is made from the conatined part.... !@
- NB: basemap layers are there to improve display performance!!! 
- Also: make sure the data frame co-ord sys matches the image co-ord system for display speed!!! 

- Spatial references:
--------------------------
  - Consist of (1) co-ord system, datum and ellipsoid & projection
  - Has a unique id and std format of defn
  - The comments regarding Mercator and Plate Carree / Equirectangular on the sharpgis site seem to be wrong.  Mercator is a modified
  cylindrical projection, x sizes are stretched as you move away from the equator.  However, y is also strecthed to match the x stretch
  so that at any point the x,y scales are equal.  The Plate Carree / Equirectangular proj is also a cylindrical proj but without any scale
  adjustment "The projection maps meridians to vertical straight lines of constant spacing for meridional intervals of constant spacing, and 
  circles of latitude to horizontal straight lines of constant spacing for constant intervals of parallels. The projection is neither equal 
  area nor conformal."
  (1) - Geographic co-ord system (GCS) most common i.e. polar sys with angles for lat and long and radial len from datum/sea level as height
      - Geocentric is a cartesian system used in GPS calcs but rarely displayed to the user.
	  - Another is the Easting/Northing system which is cartesian projected onto the surface of the ellipsoid.  This must be similar
	  to the GCS but slightly warped due to it being projected onto the ellipsoid rather than spherical angles.  NB a common eg is the
	  UTM.  Is this projection onto the ellipsoid the TM projection?  Or is UTM commonly used with the TM projection??  
	  (Wrongly) called "Cartesian".
	  - Shperical systems also need a prime meridian to define a ref for vertical co-ords.
	  - Latitude(y) values are measured relative to the equator and range from -90° at the South Pole to +90° at the North Pole. 
	  Longitude(x) values are measured relative to the prime meridian. They range from -180° when traveling west to 180° when traveling east.
	  - On the Clarke 1866 spheroid, one degree of longitude at the equator equals 111.321 km
  (2) - The above co-ord systems are relative to a centre and for some (eg no 3 - "Cartesian") need an ellipsoid to define the x/y dimensions
      Possibly all require an ellipsoid to define heights.
      - The datum defines centre and orientation of the ellipsoid.
	  - The earth is not a spheroid.  Datums are chosen to match sea level best in a local region.
	  - Due to continental drift, datums are defined at specific times
	  - A common datum is WGS1984 that I think is fairly accurate globally
	  - The datum defines the origin and orientation of latitude and longitude lines.
  (3) - The earth is not flat so a projection is needed to flatten geographic data onto a map.
      - Various projections are designed to preserve different attributes eg the Mercator projection preserves angles. 
	  - Mercator is what is seen most commonly eg on Google maps.
	  - There is always a projection.  Sometimes lat/long are projected directly onto x/y.  This is called equirectangular or "Plate Caree".
  - See the NGI site on this topic.  The LOx system refers to the Gauss conformal projection with a x longitudinal offset.  The hartebeeshoek94
  datum uses the WGS84 ellipsoid and a "hartebeeshoek"94? pose, scale & offset/origin (i.e. datum). This is the spatial ref used by NGI.
  - UTM is both a datum (which is WGS84) and a co-ord system which is "cartesian" or TM projection which I think amounts to similar/same things.
  It is not a projection but it used a series of TM projections to achieve min distortion and ease of dist calc.
  "The UTM system is not a single map projection. The system instead divides the Earth into sixty zones, each a six-degree 
  band of longitude, and uses a secant transverse Mercator projection in each zone." " it preserves angles and approximates shape but distorts 
  distance and area" - Wikipedia.  Horiz distortion is min by dividing into zones.  Vert distortion is min by orienting the cylinder horizontally
  "Calculating the distance between two points on these maps could be performed more easily in the field (using the Pythagorean theorem) than was 
  possible using the trigonometric formulas required under the graticule-based system of latitude and longitude." seems to be the main point.
  I guess it can be warped into a projection by flattening and rectangularizing each of the UTM zones.  No standard geocentric based projection
  makes sense.
  - Mercator proj is a proj onto a vert cylinder, Xverse mercator is a proj onto a horiz cylinder.
  
Some notes on datums, ellipsoids & software support
----------------------------------------------------
- NGI allegedly uses the Hartebeeshoek94 datum which is based on the WGS84 spheroid.  In practice it seems they use plain WGS84.
- Hartebeeshoek94 is recognised by PCI but not GDAL or ArcMap.  GDAL defaults to WGS84 SMajor&SMinor - what about the pose??.  
Not sure what arcmap does - but it does not recognise it.
- Seemingly PCI claims to recognise it but writes out 0XFF for ellipsoid, datum etc
- gdalinfo, geotiffinfo.m both show that relevant fields have not been populated by PCI for Hartebeeshoek94.
- Both GDAL and mapping toolbox default to WGS84
- There is no EPSG code for Hartebeeshoek94

- A datum consists of a reference ellipsoid and co-ord system center and alignment.  It is necessary to convert GCS positions 
into real earth positions.  
- "Because the Earth is an imperfect ellipsoid, localised datums can give a more accurate representation of the area of coverage than the global WGS 84 datum. However, as the benefits of a global system outweigh the greater accuracy, the global WGS 84 datum is becoming increasingly adopted."
- WGS84 is a "horizontal" datum...
- A vertical datum is used for measuring the elevations of points on the Earth's surface. Vertical datums are either: tidal, based on sea levels; gravimetric, based on a geoid; or geodetic, based on the same ellipsoid models of the earth used for computing horizontal datums.
- It is important to note that geodetic latitude (\ \phi) (resp. altitude) is different from geocentric latitude (\ \phi^\prime) (resp. altitude). Geodetic latitude is determined by the angle between the normal of the ellipsoid and the plane of the equator, whereas geocentric latitude is determined around the centre (see figure). Unless otherwise specified latitude is geodetic latitude.

EPSG
----
- There are EPSG codes for various standard geographic measurements/things (like ellipsoids, datums, GCS & PCS)
- The output from gdalinfo is informative: eg
-   GEOGCS["WGS 84",
        DATUM["WGS_1984",
            SPHEROID["WGS 84",6378137,298.257223563,
                AUTHORITY["EPSG","7030"]],
            AUTHORITY["EPSG","6326"]], //for the datum
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4326"]], //for the GCS
    PROJECTION["Transverse_Mercator"],
    PARAMETER["latitude_of_origin",0],
    PARAMETER["central_meridian",23],
    PARAMETER["scale_factor",1],
    PARAMETER["false_easting",0],
    PARAMETER["false_northing",0],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]]]
- Things seems a bit more complicated and confused than this in the wild
- See: http://www.epsg-registry.org/ "retrieve by code" 
 
ZIPPS
------ 
  Testing on job 319 and checking how it matches to "My Calibrated"
- The bands within a ZIPPS image match well 
- They dont quite match to the "My Calibrated" images but are v close - prob good enough
- The colours dont match up but we have obviously excluded the dodging

  
NGI
------------------
  - The unrectified imagery does not match up radiometrically between jobs that were flown a week apart in Feb (when there's little rain) 
  - I was able to rectify "Calibrated" imagery with SUDEM using the Aero-Triangulation.  Accuracy needs further investigation.  
  We need to check distortion as we are not considering this at present.  
  We need to get the GPS/INS data to make sure we are not using this but rather the aero-triangulation.

Rectification
------------------
  - Exterior orientation = the pose of the camera.  This can be obtained from GCP's, TP's and DEM (or stereo heights?) (need to understand better).  
    Thene there are also the interior params like DISTORTION and principal pt.  
  - The GPS/INS data is essentially exterior orientation.
  - The aero-triangulation data is also the exterior orientation but should be a refined version of GPS/INS.  The refining is done using GCP's
    and TP's.  
  - I was able to use the aero-triangulation to rectify "CALIBRATED" imagery (see notes in NGI).  No consideration was given to internal params
  like distortion and principal point.
  - Rectifying with the aero-triang seems to produce a somewhat systematic error with the rh image being shifted left compared to the lh image.
  It seems as if the DEM is in the right place i.e. like the images are being projected onto the dem incorrectly.
  So it could be some problem with the co-ord sys definition or projection ?? 
  - Another look points to the systematic error being projection as it looks like the ims match with the dem in the middle but are more stretched 
  towards the outside.  The spatial ref looks wrong in arcmap compared to what I asked for in pci
  - Rectifying with the plane's GPS/INS produces seemingly random errors.
  - I had the ext orientation spatial ref wrong.  Dont follow Garth's notes.  It is GCS: Lo21, Datum: Hartebeeshoek for the output spatial ref and
  NNNB GCS: Lo21, Ellipsoid: WGS84 for the ext orientation (input) spatial reference.
  - The aero-triang rectification is definitely better than the gps/ins rectification.
  - Using hartebeeshoek datum makes sense but contrary to advertisement NGI seems to be using plain WGS84.  Also GDAL doesn't seem to recognise hartebeeshoek.  The choice in PCI datum/ellipse is either or not both and
  - To set output dir: on 1st run - before anything else, select all files and shift to process box, select dir for 1st file, rest are auto named
  
  Oct 2017:
  - NB: The coord sys of the NGI Aerotriang / exterior orientation files is contained in the filenames eg *Lo25Wgs84.* means TM 25 with datum=WGS84.  It is the same projection as the unrectified NGI supplied images.  Note that it is datum and not ellipse = WGS84.
  - If there are not enough (all?) images covered by the DEM, PCI gives an error after a v long wait.  To avoid this, set a clip region to the valid DEM and also only load relevant NGI images.
  - Do not setup TIF jpeg compression for output format as PCI gives an error about 16bit files. 
  - PCI builds internal overviews by default. 
  - The hartbeeshoek94 datum files report a proj4 string as ellips=WGS84.  If this is right it means CGA is screwing up.  
  - NNB "The difference between Hartebeesthoek 94 coordinates and WGS84 as used for the reference frame of GPS is approximately 0.2 m and 0.3 m in Lo y and x coordinates respectively. Therefore coordinates in these systems can normally be assumed to be coincident for most GIS applications."  http://www.georeference.org/forum/t115330
  i.e. we may not know if we are incorrectly using Hartebeeshoek94 or WGS84
  
GDAL
----------------
 - A GDALDataset has a 3x2 affine xform matrix to project from image to projected space.  It is called GeoTransform.  It is the same as the camera intrinsic matrix in the camera model and the "SpatialReference" in the mapping toolbox.
 - A GDALDataset contains a string defining the projection.
 - OGRCoordinateTransformation can be used to xform co-ords betw projections
 - GDALWarpOperation etc can be used to warp rasters to different projections.  The output image size is supplied then it seems to work out the gridding internally.  You can supply source and dest GeoTransforms too which may be able to control the gridding as you want it.  I assume you can make it resample images in the process.
 - Locations can be held in a GDALRasterBandH as if they were pixels and transformed with GDALTransformGeolocations
 - There is a function to grid irregular data
 - Also has connected components, 
 - GDAL_merge.py has mosaicing fn with definable output res
 - Includes "The OGR Simple Features Library" for vector rw and manipulation
 - Need to install 64bit python + separate gdal python package for python scripts, then set env vars GDAL_DATA & PATH - see shell script in install dir
 - PATH must start with GDAL directorty for python to work ????
 - NB: You can align output pixel grids using gdalwarp with the "-tap" option.  See http://blogg.uit.no/thk031/2013/05/04/re-projecting-images-to-the-same-grid-using-gdal/.  The only thing is that it seems to make NODATA borders if the window is not >50% filled.
 - -tap and grid alignment: 
 
 BUILDING GDAL FROM SRC
 - NB Note: maybe you dont have to build from source, you can get compiled libs etc from eg http://www.gisinternals.com/sdk/PackageList.aspx?file=release-1600-gdal-1-10-mapserver-6-2.zip
 ACTUALLY these dont have the compiled libs but I see there are some in Toolboxes/GDAL which maybe came from the first link below.
 - NB Note 2: There are 2 places you can get source distr from: eg http://www.gisinternals.com/sdk/PackageList.aspx?file=release-1600-dev.zip and http://trac.osgeo.org/gdal/wiki/DownloadSource.  The first site contains the compiled binaries for different compilers. Yay!  WIth HDF etc???? - NO
 - Otherwise...
 A   - See http://trac.osgeo.org/gdal/wiki/BuildingOnWindows
	 - Edit dirs in nmake.opts (does not like paths with spaces)
	 - Remember 64/32 bit python differences i.e. set path to point to relevant python dir, set GDAL_DATA env var
	 - I didn't succeed (or try very hard) in building the python stuff - instead download bindings from http://www.lfd.uci.edu/~gohlke/pythonlibs/
	 - Install the above and make sure PYTHONPATH env variable doesn't point to any gdal stuff, this install will take care of that
	 - Uninstall any other pythons other than the one you are using, you may need to re-assoc .py with python etc
	 - Copy python scripts into bin dir
	 - Weird file assoc issues eventually led me to reinstall 32bit python - actually .py had wrong file type assoc in registry!!!
	 - Install NumPy
	 - Added support for hdf4 (download from http://www.hdfgroup.org/release4/obtain.html and configure in nmake.opt) - except it doesn't work...
 B - use http://www.gisinternals.com/sdk/PackageList.aspx?file=release-1600-dev.zip and link to the precompiled libs
   - the precompiled libs do not support hdf 
   - OsGeo4W also includes some GDAL lib files and is compiled with HDF! IT WORKS!!! And I can link in GDAL!!!!  Set PYTHONHOME to C:\OSGeo4W\apps\python27
   
   - There are matlab and r bindings for gdal
   
   OGR:
   - to create polygon from raster use GDALPolygonize (VERY SLOW - rather use ArcGIS which can polygonize mosaics)
   - to merge polygons (eg from tiles in mosaic) use cmd line ogr2ogr (doesn't do geometrical union though just concats)   
   -   or OGRGeometry.Union(...) or OGRGeometry.Intersection(...) programmatically (which should do a proper geom union)
   - VRT can also be used for merging\'
   
OpenCV
-------
- Can load GeoTiffs but only the first band, fairly easy to convert from GDALDataset to cv::Mat though
- mexopencv provides bindings for matlab.  This provides a handy way to test opencv inside matlab.  Matlab-OpenCV data IO also easy with cv.FileStorage
- There are also "official" matlab bindings in the github opencv tree now
- SVM results compare well with prtools (when using internal RBF) and seem pretty fast.  The only issue is that it doesn't seem to support soft labels / prob outputs which is useful for the canopy cover but not essential
- OpenCV RTrees gives good results, not identical or quite as good as prtools librandomforestc but good enough.
- OpenCV can handle larger datasets than prtools and its ML is faster
- OpenCV PCA eigvecs and vals match matlab eig(cov) but not prtools pcam. Prtools pcam finds cov of a prior weighted dataset and does some other adjustments.  Ultimately it uses matlab's eig though so we should be able to replicate in opencv.  Pcam does an affine mapping with offsets, OpenCV PCA does only projection, no offsets.
- OpenCV mat are ordered by row, matlab are ordered by col
- Beware that mexopencv does not save classifiers to yaml correctly.  Rather save the training set to yaml, then train in c++.  This seems to give equiv results to matlab.
- *2016 - Now supports GDAL but not sure about mult bands - yes I think so - see http://docs.opencv.org/3.0-beta/doc/tutorials/highgui/raster-gdal/raster_io_gdal.html
- NB Note, you can download compiled binaries http://sourceforge.net/projects/opencvlibrary/files/opencv-win/3.1.0/

Mapping Toolbox
-----------------
- Similarly to GDAL, "SpatialRef" refers to a instrinsic mat type affine xform to go from pixel to projected space.
- There is no uniform way of specifying projections, geotiffinfo must be parsed appropriately and passed to axesm
- There are functions to convert co-ords betw projected and georef systems but nothing to xform images betw different co-ord systems.  The image pixel co-ords must be constructed in the xformed space and then backprojected into the source space.  Then the image interpolated at these backprojected co-ords to get a transformed image.  While this is clumsy, it at least creates transparency about where exactly your pixels lie in whatever space you are using
- mapshow shows whatever in whatever space it is in.
- geoshow will project whateber into whatever the  co-ord sys/proj of the axes is
- axesm is used to create axes with specific projection.  There is no way of passing geotiffinfo to this directly
- Visualisation is very slow and possibly buggy
- There are fn's to convert between pixel/projected co-ords, regrid data etc

MODIS
-----
- Reverb is best data source to use
- HDF format is arcmap, gdal(compiled with support) and matlab compatible
- MYD09Q1: MYD09Q1 provides Bands 1 and 2 at 250-meter resolution in an 8-day gridded level-3 product. The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.  Bands 1-7.
- MCD43A4:  provides 500-meter reflectance data adjusted using a bidirectional reflectance distribution function (BRDF) to model the values as if they were taken from nadir view. The MCD43A4 product contains 16 days of data provided in a level-3 gridded data set in Sinusoidal projection.
- MCD43A4 also known as NBAR
- MOD09A1 provides Bands 1–7 at 500-meter resolution in an 8-day gridded level-3 product. The MODIS Surface Reflectance products provide an estimate of the surface spectral reflectance as it would be measured at ground level in the absence of atmospheric scattering or absorption. Low-level data are corrected for atmospheric gases and aerosols, yielding a level-2 basis for several higher-order gridded level-2 (L2G) and level-3 products.
- Use DownThemAll right-click->advanced->import from text file to download 
- Drawing HDF in acrmap happens in geological time (it doesn't make pyramids) - convert to geotiff
- Note that bands 8-19 cover the vis range fairly well in small increments.  Could these be summed to more closely match NGI?  They are 1000m res though and I dont see them in any of the available products.
- There is a tool called "HEG" that can convert hdf to geotiff, reproject etc http://newsroom.gsfc.nasa.gov/sdptoolkit/HEG/HEGHome.html
- There is another MRT that I prefer (is simpler and works - default proj params are not correct though)
- Apparently the default MODIS datum is NO_DATUM and actually needs to be converted to WGS84 (check this)
- The MRT conversion insists on doing the bands separately though!
- Note that MCD43A4 measures "Nadir BRDF" wheras MOD09A1 is "Surface Reflectance".  These are not the same things and the images are quite distinct.

SPOT
-----
- Spot 5 launched 2002
- "SPOT 5 has two high resolution geometrical (HRG) instruments that were deduced from the HRVIR of SPOT 4. They offer a higher resolution of 2.5 to 5 meters in panchromatic mode and 10 meters in multispectral mode (20 metre on short wave infrared 1.58 – 1.75 µm).[3] SPOT 5 also features an HRS imaging instrument operating in panchromatic mode. HRS points forward and backward of the satellite. Thus, it is able to take stereopair images almost simultaneously to map relief."
- Seemingly has no blue band. - P (panchromatic) ; B1 (green) ; B2 (red) ; B3 (near infrared) ; B4 (SWIR : short-wave infrared, for SPOT 4 and 5 
- Revisit interval: 2 to 3 days, 1 day with full constellation of Spot satellites
- "Level 1A imagery is corrected by normalizing CCD response to compensate radiometric variations due to detector sensitivity. "
- Levels after this only correct for geometry, so there is no BRDF corrected product
- Bands:
	Panchromatic, 2.5/5m, 0.48 - 0.71 µm
	B1 : green, 10m, 0.50 - 0.59 µm
	B2 : red, 10m, 0.61 - 0.68 µm
	B3 : near infrared, 10m, 0.78 - 0.89 µm
	B4 : mid infrared (MIR), 20m, 1.58 - 1.75 µm
  These are reasonably close to NGI and not v close to MODIS
- catalogue.sansa.org.za.  
	- Check the metadata by clicking "i" for info.  You will see spatial res and processing level. 
	- Proc only level 1B which means no GCP orthorect
- Get level 1A then orthorectify and atcor using PCI
- Metadata.dim file is xml containing all calib info.  Can be viewed in firefox.
- To ATCOR SPOT tif, first convert to PCI .pix, gdalinfo on the .pix will then give the channel mappings, gains etc 

ATCOR (PCI) SPOT
-----------------
- First orthorectify the SPOT image in PCI
- Despite unit confusion, use the offset/gain figures as they are in metadata.dim to make .cal file.
- Beware of the channel->band mapping.  The ordering in the orthorectified tiff is 3,2,1,4 - specify it as such.
- There is seemingly no figure for the satellite azimuth so I ommitted this.  Use the viewing angle from the metadata for the satellite elevation.  The incidence angle in the metadata refers to the earth side angle corresp to the viewing angle i.e. it is not azimuth.
- Settings: no brdf, haze etc.  Vis=40km, Rural, dry
- Use arcmap to convert atcor'd .pix to .tif.  GDAL has an issue???
- The important params for path radiance (additive component) are visibility, aerosol type and water vapour.
- Adjacency is usually ignored
- Google "SPOT – Sensors in ATCOR" - see http://wenku.baidu.com/view/b0e5f9878762caaedd33d46a.html for a good doc on SPOT params for ATCOR / Geometry_and_Calibration_Files_for_SPOT_in_ATCOR.pdf in Mendeley
- View/tilt and incidence angles in metadata.dim are both measuring the same thing (see Geometry_and_Calibration_Files_for_SPOT_in_ATCOR.pdf Fig 1)
- Satellite azimuth is given by 90 + orientation angle (from vol_list.pdf or SCENE_ORIENTATION in metadata.dim) if tilt/incidence angle is -ve OR
								270 + orientation angle (from vol_list.pdf) if tilt/incidence angle is -ve
- NB note: ATCOR does a pretty good terrain correction when the DEM is specified under "Elevation" but this does not match well with our XCalib.  So rather use const elevation.  I think this is also where the ATCOR BRDF correction comes in.  i.e. the terrain correction assumes a lambertian surface which esp for extreme angles is not true, so the BRDF changes away from ideal lambertian to rough guess as to what is typical (and this esp changes the behaviour for extreme angles)								
- Options used:
  - Viewing geom + band cal from metadata.dim
  - No cloud mask, no water mask, no haze removal
  - Elevation from DEM, calc dem deriv, calc illum map  
  - Aerosol type: rural, condition: dry
  - Sensor viewing angle: metadata.dim - "VIEWING_ANGLE" - NB take abs value!
  - Sensor azimuth: 90 + 14.710456 (see Geometry_and_Calibration_Files_for_SPOT_in_ATCOR.pdf Fig 2)
  - Elevation: const ~700m
  - Constant visibility 40km
  
  
HDF
---
- GDAL can be compiled to support HDF but available binary versions do not support it.  Except the OSGEO4W version allegedly has HDF support!
(Wow - that actually works!!!!)
- There is a tool called "HEG" that can convert hdf to geotiff, reproject etc http://newsroom.gsfc.nasa.gov/sdptoolkit/HEG/HEGHome.html
- There is also MRT, the MODIS reprojection tool https://lpdaac.usgs.gov/tools/modis_reprojection_tool
- THE HDF format is a generic format with no geoloc info, thus NASA developed HDF-EOS which includes geo-loc
- It is self describing like xml
- Reverb supports HEG and MRT services on some data - see http://earthdata.nasa.gov/about-eosdis/news/mrt-and-heg-processing-services-available-through-reverb
  - You can set this up when you check out your cart - you have to input similar paramters to HEG/MRT though
- Gdal in OSGEO4W supports HDF


OSGEO4W
--------
- Includes GDAL with HDF support, as well as GDAL libs and headers that work
- My joy with OsGeo4w was short lived.  I installed OsGeo4W quantum, udig etc after GDAL, now HDF + -proj4 options dont work with GDAL.
OK, now I reinstalled just GDAL using the advanced OsGeo4W install option and it works again
- There is an OpenCV package...
- Does not include the very latest GDAL
- Set PYTHONHOME to C:\OSGeo4W\apps\python27
- Set PATH to C:\OSGeo4W\apps\python27\Scripts; C:\OSGeo4W\bin
- The Osgeo4w version of python fights with the arcgis version, Somehow when arcgis is installed it tries to use the arcgis python to open/run scripts although I don't see anywhere in env vars that this is set up. I has to manually set the above env vars to get the osgeo4w version working.  .py file assoc can also be an issue.  I ended up using the sourceforge utility Type to assoc .py with the OsGeo4w python - add "open" action and set to "C:\OSGeo4W\bin\python.exe" "%1" %*.

QUANTUM QGIS
------------
- Raster rendering:
  - Both tiles and overviews will improve speed
  - Overviews: use jpeg compression for min size (lossy doesn't matter for overviews) and for speed but don't use the --config PHOTOMETRIC_OVERVIEW YCBCR --config INTERLEAVE_OVERVIEW options that QGIS inserts by default as they are intended for RGB images and will fix the colormap and prevent CIR display.  Beware of jpeg overviews with mosaicing boundary artefacts issue below.  Adding extra/higher level (Oeg16) overviews wont add much overhead or space.
  - Keeping overviews external is perhaps unwieldly in file management but is default for ARC and does allow separation of core source data from derived data for backup i.e. let's use external overviews
  - QGIS rendering seems slower than arc but remember the files are now DEFLATE compressed 
  - Consider ECW format for size and speed http://linfiniti.com/2009/09/image-mosaicking-with-gdal/.  But remember it is LOSSY and proprietary
  - Tiling: helps in close-up by loading blocks that are displayed rather than entire rows.  My xcalib source files are tiled.
  - NB "(From GDAL 1.8.0) The block size (tile width and height) used for overviews (internal or external) can be specified by setting the GDAL_TIFF_OVR_BLOCKSIZE environment variable to a power-of-two value between 64 and 4096. The default value is 128."

- Raster mosaics:
  - A VRT of many rasters can easily be made.  
  - A VRT of rasters each with their own overviews displays in the order of seconds and is usable.  But.. it has weird artefacts between individual rasters that only disappear when you zoom right in.  Is this something to do with JPEG overviews??? - Quite likely.  Yes - "deflate" overviews get round this problem but they are big size and perhaps a little slower to display/
  - A VRT of rasters with jpeg overviews built on VRT gets around the boundary artefact problem too.  But ideally the overviews for a big mosaic should be tiled which this is probably not.  What about the GDAL_TIFF_OVR_BLOCKSIZE?
  - Mosaic jpeg overviews built with gdaladdo ... --config GDAL_TIFF_OVR_BLOCKSIZE 512 ...: no noticable rendering improvement for my test mosaic of ~ 10 images 
  - Another option: gdaladdo -r average --config COMPRESS_OVERVIEW DEFLATE --config GDAL_TIFF_OVR_BLOCKSIZE 512 --config PHOTOMETRIC_OVERVIEW YCBCR --config INTERLEAVE_OVERVIEW PIXEL
  - See http://linfiniti.com/2009/09/image-mosaicking-with-gdal/ .  Make tiles manually from vrt mosaic with gdal_translate.  Then mosaics those tiles (which have their own overviews?).  Interestingly, ECW tiles are faster than gtiff!  
  - NB "ECW format does not support creation of overviews since the ECW format is already considered to be optimized for "arbitrary overviews". " i.e. overviews are implicit in the wavelet compression
  - gdaladdo -r AVERAGE -ro --config JPEG_QUALITY_OVERVIEW 75 --config COMPRESS_OVERVIEW JPEG --config GDAL_TIFF_OVR_BLOCKSIZE 512 --config BIGTIFF_OVERVIEW YES  2 4 8 16 32
  - A vrt mosaic with no overviews of its own but with overviews of its component rasters is slow to display for 100s of rasters (some seconds per zoom) but not unusable 
  *- does it actually use the component overviews when it is zoomed in?  It does use them when loading the mosaic as there is a noticable differernce in load time for mosaics with and without overviews.  Zooming is also slower. BUT zooming a vrt mosaic with component overviews is slower than zooming one of the components. 
  - Try adding only coarsest overviews to vrt mosaic eg "gdaladdo -r AVERAGE -ro --config JPEG_QUALITY_OVERVIEW 75 --config COMPRESS_OVERVIEW JPEG --config GDAL_TIFF_OVR_BLOCKSIZE 512  3321D_2010_319.vrt 32 64 128 256" combined with the finer overviews per mosaic component.  Result: VRT overviews override component raster overviews so when it gets down to individual image scales, the zooming becomes slower than it would be if zooming that image on its own.  It is a usable speed though.  
  - See notes here http://lists.osgeo.org/pipermail/gdal-dev/2012-April/032650.html and http://osgeo-org.1560.x6.nabble.com/gdal-dev-Scale-dependent-VRT-for-overviews-td4966814.html - perhaps the second option will be useful to us.  
  *- One could use "scale dependendent visibility" in qgis to show different mosaics at different zooms.  Eg you have one vrt mosiac with its own overviews at coarse levels - you only show this at coarse scales.  Then you have another VRT mosaic without its own overviews but with overviews for each component.  You then display this at fine scales.  This seems like the best compromise for now.
  - ECW format seems like a really good solution to all this but is proprietary
  - See also VRT tutorial - it is quite rich

Anaconda
--------
- Delete PYTHONHOME from C:\OSGeo4W\apps\python27
- Install with options for setting env vars selected
- Maybe reinstall OSGEO4W w/o python? & with QGIS?

Remote Debugging
----------------
- http://www.codeproject.com/Articles/146838/Remote-debugging-with-Visual-Studio-2010
- Possible over VPN but seems like accounts and permissions could be a problem.  Can use NoAuthentication mode if Theo permits.
- Not supported in 2010 express (I have checked this!)
- Seems like it should be possible to set up remote debugging to work assuming, SUN doesn't have external firewalls.  (with admin rights on SunGis08)
- "Unfortunately Windows Authentication mode requires the same account to be setup on the host and the remote computer – both usernames and passwords must be the same"
- Not clear if 2012 express supports remote debugging

Cross Calibration
- Ray Matching: simple method: assumes similar time, viewing geometry, spectral responses.
- Radiatice Transfer Modelling: takes viewing geometry (& spectral responses?) into account.

EASI
-----
- PCI's scripting language
- Arrays:
  assignment: VECTOR=1,2
  decl: integer x[3]
  acc: x(3)
- Structures supported
- "Modelling": 
  - expressions support vars as channels or bitmaps
  - "The special extensions include the ability to use channels in the expressions and a number of special modeling variables.  To understand the limitations of modeling expressions it can be helpful to realize that modeling expressions are evaluated in "chunks" over the whole requested region. Each operation in the expression is done over a chunk, taking zero or more blocks of image data as input and creating an output block of image data. This means that modeling expressions cannot generally be used in place of numeric expressions unless the function treats modeling values specially. 
  - eg filter: (channel 7  = filtered version of channel 4)  
  MODEL
   %7 = (%4[@x-1,@y-1] + %4[@x,@y-1] + %4[@x+1,@y-1] +   \
         %4[@x-1,@y  ] + %4[@x,@y  ] + %4[@x+1,@y  ] +   \
         %4[@x-1,@y+1] + %4[@x,@y+1] + %4[@x+1,@y+1] ) / 9
  ENDMODEL
  - eg LUT
  %1 = lut[%1+1]
  - each channel can have a mask ("bitmap")
  - NNB: these below refer to ops on the entire image as above
    @x: current x (pixel) processing location 
	@y: current y (line ) processing location 
	@dbx: size of database in x (pixel) direction 
	@dby: size of database in y (line ) direction 
	@meterx: size of a pixel in x direction in metres 
	@metery: size of a pixel in y direction in metres 
	@geox: x georeferenced centre of current pixel 
	@geoy: y georeferenced centre of current pixel 
	@sizex: x size of a pixel in georeferenced units 
	@sizey: y size of a pixel in georeferenced units 
- usual flow control constructs  
- Projections:
  - EASI includes intrinsic functions for accessing projection information from database files and for translating points between projections. 
  - The Reproject() intrinsic function translates coordinates between projections. This function takes a list of coordinate pairs stored in an array and a pair of GeoInfo structures that define the input and output projections as input. 
- Supports math functions  
- Params for a procedure set up over mult lines + ind vars
- EASI>a = a + b + 1, EASI>print a,  11
- Includes vector (eg polygon) operations
- "Modeler" modules (various higher level algorithms like interp and reprojecting) can be called from EASI
  - REPROJ module can be used for reprojecting images, can specify output pixel spacing and UL, LR bounds
  - RESAMP can up/downsample an image
  - Many others
  - The "modeler" module librarian can be used to search fn's
- In summary, the req's for a simple x-calib seem to be satisfied  

Cross Calibration
------------------
- See http://www.geog.ubc.ca/courses/geob373/lectures/lecture09.html
- Theoretical foundations in terms of spectral overlap and different spatial res are suspect.
- Spatial res, aliasing, viewing angle, topography, sensor spectral & spatial char all affect image in non-lin ways. Cross calib assumes can be approx by simple linear model.
- Note that MCD43A4 measures "Nadir BRDF" wheras MOD09A1 is "Surface Reflectance".  These are not the same things and the images are quite distinct.  Some pixels in MOD09A1 look a bit suspect but it is worth trying.  Even the surface refl on a specific day is worth looking at.

- Some observations on my method + results:  The OLD_GAIN_CODE option upsamples the gains incorrectly and should not be used.  Working with interpolated/smoothed upsampled gains means that a downsampled version of the final xcalib image will not match the modis ref exactly (the upsampled gains will not downsample to the same vals as the were orig downsampled from).  This can also mean there are slight discontinuities between adjacent images (upsampling by the border of one image will not make the same gains as upsampling inside the border (in the same spatial loc) on the second image).  This could be overcome by xcalib and then removing the suspect boundary / setting to nodata.  
- We dont want to use partial downsampled pixels (downsampled pixels not fully covered by src data) in the calculation of gains.  All gain border pixels are set to 0.  This does not address the above issue.  This can get a little confusing when running the XCALIB_DEBUG version of the code as it can happen that >1 border pixel needs to be eliminated after INIT downsampling.

- 2015:
- When downsampling, modis res pixels that are not entirely covered by dmc pixels are set to nodata.  This is what I thought at first BUT it is modis res pixels that are mostly covered that are retained not entirely covered modis res pixels i.e. only modis res pixels that are mostly uncovered are set .  This results in gains being found for invalid/partial downsampled pixels then usampled and applied to full res pixels.  XCalib pixels in these zones will be "invalid" and will tend to create seamlines / discontinuities between adjacent images.
- In general, when gains are upsampled, all boundary zone upsampled pixels will contain extrap vals and will thus be suspect and should be set to nodata.  But only after they are upsampled! If before then we still have the same problem.
- The code assumes that by ommitting 1 border ds pixel, we make sure that only full covered pixels are used but this is not the case necessarily.  If the image is quite diagonally oriented there could be >1 border pixel not fully covered.  Also
- So the algorithm should go something like: 
   - Downsample only fully covered pixels, the rest are set to nodata.  To find only fully covered pixels: Perhaps we can make a polygon of the nodata border then use the -cutline option with gdalwarp - problem is gadal_polygonize is python.  Also we could make a nodata mask but change the nodata value to be not nodata so that it is included in the interpolation.  Then downsample the mask using averaging and only use pixels use average shows they were completely covered.  
   - Find gain and upsample as is
   - Erode the nodata boundary by 1 (1/2?) modis res pixel to get rid of extrap pixels
   - USE NUM_THREADS warp option! http://www.gdal.org/structGDALWarpOptions.html#a0ed77f9917bb96c7a9aabd73d4d06e08 
- What does dfErrorThreshold in gdal_warp do?   
- Applying the above changes does change things and improve them (for my experiment site). Seamlines and hotspots still remain but are reduced.  It is not a big improvement and I don't think there is a good case for reprocessing & classifying the whole xcalib dataset as I don't expect much improvement.   
- When looking at the data in a natural colour rendering (i.e. not contrast stretched), seamlines are barely visible.
- NB seamlines arise because of brdf and perhaps atmospheric effects, the principle should be to deal with the source of the problem and demonstrate that it has been dealt with.  From this perspective, it is not that valuable to include plots of seamlines
- Comparing MODIS im with NGI xcalib images downsampled (cubicspline) to MODIS res and mosaiced: they are reasonably similar, the ngi mosaic is a bit more contrasty and not as smooth as the modis mosaic.  There appear to be some spatial errors.  Also shadowing in NGI is not present in MODIS.  How do these differences arise:
  1) When downsampling xcalib NGI images and mosaicing them, the last pixel to fall in a "bin" is the one that is used.  This, in combination with the fact that the downsampling is not limiting itself to 100% modis res pixels (as described above) means that some ds modis res pixels will have "invalid" values in them.  So, we should really reapply the xcalib with the new algorithm, so that we have only 100% covered pixels.
  2) The PSF of the modis sensor is wider than a pixel and thus it is a blurred/smoother version of the ngi image which does not simulate this effect.  In fact we want to keep the resolution of the ngi image rather than smooth it out.  Thus perhaps another motivation for cubicspline us.
  3) As the cubicspline US does not follow the modis im exactly but is also affected by the ngi image and the continuity/smoothness constraints, Shadows in the ngi image, plus other details will affect the end product.  While one may expect the ngi ds mosaic to be smooth because of the use of cubicspline us and ds, it is smoother than what it would be if average ds was applied directly from either raw or xcalib ims.  
  4) The smoothness aim in the xcalib algorithm is for the smoothness of the calib param (brdf and atmos effects), not the smoothness of the end result.  So discontinuities/contrasts in the raw ngi image will still find their way into xcalib result although they should be somewhat smoothed themselves.  This is observed in the ds raw and xcalib mosiacs. i.e. spatial discont trends present in the raw find their way into the xcalib.  this is probably a good thing.
- Spectral sensitivities:
  - Remember that the assumption is linearity over the sliding window, which applies to the spec sensitivity rel too.
  - Most typical surf refl are pretty smoothly/gently varying over visible range so quite forgiving on linearity of spec sensitivity which is not bad even over all investigated land cover types as opposed to over 1 or two inside a sliding window.
  - Incl smoothness constraints in interpolation, will help overcome sliding windows containing much spectral variation
  - blue is the worst correlation betw modis and dmc.  looking at the combined rsr's & surf refl, the most variation is in this band.  so this makes sense.  utlimately blue is not that informative for vegetation and is the most susceptible to haze / atmostpheric effects
  - even though nir spec sensitivities are quite different, rel is pretty linear
  - TO DO: get more aster surf refl, sort out confusing matrix code, interpolate better / differently, MODIS UCSB Emissivity Library Home Page - TIR 
  - Notes on results in papers to incl (?):
    

MISR
-----
- Is able to characterise earth surface / lan covers in terms of their directional scattering behaviour (which is different for different surfaces/covers) and thus provides more info than only nadir
- A lot of the usefulness of the mult angles is in the study of aerosols and clouds.  Also albedo.
- A lot of emphasis is placed on calibration.
- See detailed radiometric info + spectral sensitivities at http://www-misr.jpl.nasa.gov/Mission/valwork/mivcalres.html
- The MISR order and customization tool also includes a reformatting feature, which allows delivery of products in conventional HDF-EOS format, rather than MISR's special stacked-block format.
- The MISR Level 3 Products are global or regional maps of select parameters from the Level 2 products and associated covariances reported on various geographic grids depending on the data product. Parameters from multiple orbits are combined to make complete Level 3 global maps at daily (D), monthly (M), quarterly (Q), and yearly (Y) time scales and regional maps associated with field campaigns at daily and monthly time scales.
- *NB: The variances/covariances mentioned above would be interesting to look at.
- FMI below
- To accomplish its scientific objectives, the MISR instrument measures Earth's brightness in 4 spectral bands, at each of 9 look angles spread out in the forward and aft directions along the flight path. Spatial samples are acquired every 275 meters. Over a period of 7 minutes, a 360 km wide swath of Earth comes into view at all 9 angles. Special attention has been paid to providing highly accurate absolute and relative calibration, using on-board hardware consisting of deployable solar diffuser plates and several types of photodiodes. To complement the on-board calibration effort, a validation program of in situ measurements are being conducted, involving field instruments, one of which is the "PARABOLA III", which automatically scans the sky and ground at many angles, and multi-angle aircraft camera (AirMISR). Global coverage with MISR is acquired about once every 9 days at the equator; the nominal lifetime of the mission is 6 years.
- For vegetated terrain, knowing the albedo more accurately may lead to improved estimates of photosynthesis, transpiration rates, and the amount of absorbed photosynthetically active radiation (PAR). These parameters play an important role in models of the way surface vegetation and the atmosphere interact. to make good measurements of the total reflected flux, Earth's surface must be viewed from many directions.
-  the albedos of vegetation canopies may contain some information about the structural state of the vegetation, such as: the amount of leaf area, leaf orientation statistics, the percentage of stems, branches, trunks, etc. Researchers have argued, on the basis of field measurements and 3-dimensional canopy modeling, that the directional reflectance characteristics (i.e., how much solar radiation is scattered from the canopy in a particular direction), is diagnostic of such canopy structure variables.
-  The primary instrument for assessing ocean productivity on the EOS spacecraft is MODIS. However, due to sun glint over a portion of the MODIS swath as the satellite passes over the equator, some imagery will be lost. This gap in the ocean color data will be partially filled by MISR.
- NB Terra carries five scientific instruments: ASTER, CERES, MISR, MODIS, and MOPITT. 
- NB The spectral sensitivities are not a great match for NGI but may be better than MODIS.  The center wavelength of each of these bands is 446, 558, 672, and 867 nanometers respectively.
- Because the important parameters for climate research are derived from measurements taken over times longer than the life of individual satellites, the only way to ensure that observed trends are the result of changes on Earth, and not in the instruments, is to provide and maintain an absolute calibration. Calibration also ensures a synergism between the various sensors operating at the same time, e.g., other EOS instruments on the Terra spacecraft, Landsat. To meet these needs, MISR is calibrated using state-of-the-art techniques. 
- The OBC consists of a pair of deployable Spectralon-coated plates that, when rotated into the field of view, reflect diffuse light from the sun directly into the instrument, where it is monitored not only by the main MISR cameras, but also (for comparison/calibration) by a set of precision photodiodes that measure the specific light levels. These photodiodes are expected to remain stable for the life of the instrument.
- The OBC data are supplemented with so-called vicarious calibration data sets when MISR observes specific ground locations at the same time as complementary in-situ instruments (on Earth's surface).
- Another technique is to make use of MISR images over desert areas. The light from these sites can be measured by our ground crew. Averaging results from these various calibration techniques gives us both the MISR calibration constants, as well as our uncertainty in these numbers.

- MINX_Doc1.pdf contains a nice summary of MISR satellite, rationale, data etc
- MISR data is available from Reverb but it is in "stacked format" which needs a special transform to unstack.
- Stacked format contains stacked 563.2 km x 140.8 km blocks and is not HDF-EOS std
- Conventional grid format data is available from http://l0dup05.larc.nasa.gov/MISR/cgi-bin/MISR/main.cgi using the customise option
- As I only really need one block for my study area, perhaps I can use stacked block format and take just the one block?
- From what I can tell, files available contain the 9 angles of the same ground area rather the 9 angles of different ground areas as is flown
- NB: Use the "MISR Browse Tool" to find cloud free orbits

- More notes after further reading
- Most products available at 275m res while MODIS is 500m res.  But albedo is only 1km.
- Only level 1 seems to conatin R,G,B,IR which is only instrument corrected not BRDF corrected.
- Levels 2 corrected measurements but seemingly no surface reflectance (?).  There are various refl qty's like BRF, DHF etc which are not exactly surface refl but are related.  These derived qty's are at 1km res.
- Levels 3 contain temporally averaged versions of layer 2 similar to MODIS 16 day vals at very coarse 0.5 deg resolution.
- In paper "Statistical comparison of MISR, ETM+ and MODIS land surface reflectance and albedo products of the BARC land validation core site, USA" they use nadir BRF to compare to MOD09 surface refl
- See my notebook and "Reflectance quantities in optical remote sensing—definitions and case studies" for more relevant notes
- The FAQ https://eosweb.larc.nasa.gov/faq-page is also useful


Notes on X Calib validation, BRDF, ...
----------------------------------
- MODIS BRDF uses a kernel model to rep different modes of scattering.  The kernel fns are dependent on view and sun angle.  Its not clear if they use a DEM but it would be at 500m which would be quite different to doing BRDF at 2.5m (BRDF is non-lin and would not average out into equivalence as lower spatial res I think)
- The sun spot is caused by varying view angle relative to sun angle over a wide angle scene.  It may also be caused/ exascerbated by specular reflectance of land cover.  It is most noticable on flat ground.
- ATCOR assumes lambertian reflectance before BRDF.  The basic version uses a linear per scene model to convert DN to ground refl.  
- The view angle will vary the amount of light measured by a pixel, from a flat constant (lambertian) source.  This is (I think) part of what BRDF corrects for as documented in the ATCOR4 manual.  
- Then different land covers have different reflectance behaviours varying with view and sun angle (i.e. they are not lambertian).  From what I can make out MODIS kernel based BRDF compensates for these factors. PCI does not use a kernel based BRDF it only includes a single threshold (see manual) for modelling non-lambertian behaviour.  
- To do BRDF, one needs a DEM to get the local view and sun angles.  The resolution of this is obviously a factor when comparing across sensors.
- i.e. MODIS BRDF and PCI BRDF are not comparable (because of the technique and maybe also because of spatial resolution)
- Fundamentally, one can't expect differnt sensors with different spectral sensitivities to compare no matter if they have been ATCOR'
d, BRDF corrected etc.
- Given only basic atcor on SPOT, it is a linear rel with 0 bias/offset, so it comes down to a simple scaling.  Thus comparing appropriately strecthed raw SPOT and xcalib NGI will be the same as comparing atcor SPOT and xcalib NGI.
- Should an image be rectified before or after atmospheric correction?  If doing BRDF with DEM, it would have to be done before atcor.  But is this not damaging pixel-light relationships that are being corrected for in atcor?  If atcor is linear per-scene, (spatially invariant), I don't think so. 
- atcor can be used per image but it is proc intensive and impractical for 1000's of images and may also create discont in the mosaic


Calib Musings
----------------
- The rel between different sensor DN's is fundamentally non-lin and surface refl dep due to differeing spectal sensitivities.  All xcalib methods seem to model the rel as linear and ind of surf refl.  
- To properly acc for different spectral sensitivities, one needs knowledge of the surface refl.  This is generally not known other than vicarious calib egs.  It can be simulated with 6S from sensor band vals etc but while this is not really questioned in the lit, it seems fundamentally suspect as there has been a bunch of necessary info lost in the coversion of spectrum to a few band vals so how can do we get this info back so easily?
- In terms of our xcalib.  Fitting 2 params to a small set of data is going to be prone to overfitting i.e. fitting to noise.  That is possibly why it is better just to use gain.  Even using just gain, it may be better to use a bigger window to improve the gain estimates.
- Generally topographic correction does not seem to be included in any corrections like BRDF but it must be important esp for rugged terrain.  
- Hopefully we can show that our xcalib deals with a bunch of corrections (that can all be approx by local linearly) simultaneously (atcor, brdf, viewing geom, topography, "relative radiometric normalisation")
- Nobody talks about the problem of point spread fn in pixels, mixing and xcalib 
- In the xcalib lit, the band relationships always (mostly) seem to be one to one.  Probably this is appropriate for satellites which dont seem to have much spectral overlap betw bands for aerials it could help to regress on all channels when sensitivies overlap significantly.
- Kernel BRDF only has per kernel gains as params.  A constant offset param can be added to deal with minimising overlap discontinuities in a mosaic scenario.  I think my concern that this way of dealing with overlap would accumulated errors is wrong as there is always the internal cost term that looks only at the BRDF kernel fit which will prevent accumulation of errors.  It is still less than clear how the sequence of per image optimisation proceeds in mosaic with overlap constraints like this.  Could it be iterative i.e. start with only the bordering 1 or 2 images that have been corrected then redo the whole lot looking at all overlap??
- It is acknowledges that per image atcor+brdf for large mosaics is proc + storage demanding.  
- My xcalib can be considered as a kind of data fusion
- Qualitatively, I think my xcalib produces smoother mosaics than what I've seen of radiometric triangulation in the lit
- One would expect atcor to be fairly consistent over 1 image.  If brdf is purely multiplicative, and atcor purely additive then perhaps these terms can be fitted separately eg 1 constant atcor additive term per image and then per pixel brdf gains as currently implemented.
- The need to perform 2ndary corrections on mosiac images to get them smooth over images poses some questions.  Either the first brdf and atcor step is not accuracte (because it requires fiddling to make a mosaic) and or the relative norm steps adds other errors to the brdf and atcor'd images.  
- The main failings of my xcalib compares to reviewed calib methods (incl RTM) seem to be (1) that there currently is no offset term. (2) we assume spectral sensitivities match betw MODIS and NGI.  (1) we can get around fairly easily although with the compromise of further decreasing the spatial res of the xcalib params by using a sliding win.  (2) we could use a rtm model like 6s to transform the MODIS pixels (at 250m res) to NGI spectral sensitivity but still at MODIS res.  Then we calibrate the downsampled actial NGI pixels to the 6S MODIS pixels rather than straight to the MODIS pixels.  
- Various radiometric triangulation approaches differ in their steps.  Some do inp atcor and brdf then mosaic norm.  Some combine mosiac norm in brdf and ignore atcor.  Some include mosiac norm through radiomtric ctrl pts.

- Lambertian is not = in all dirs but obeys cosine law wrt angle betw observer and surface normal.
- Surface refl is a BDR (from what I read and makes the most sense i.e. MODIS BRDF is applied to surface refl).
- A reflectance factor is the the refl scaled by a std lambertian reflector.
- p = pi.L/(E.cos(theta)) formula for refl factor (of lambertian surface?) note that it varies with solar angle
- lambertian means refl = in all dirs proportial to cosine betw light src and surface normal (foreshortening).  Independant of viewing angle i.e. = in all angles!!!!
- ATCOR without BRDF assumes lambertian surface therefore the refl that are output are "lambertian" assumed.
- brdf correction reqd to adjust measured refl to hypothetical nadir view and solar zenith.  if the surface is truly lambertian, it doesn't matter where it is viewed from but most surfaces are not and have non std brdf hence the need to correct to view nadir
- kernel brdf correction can be additive or multiplicative
- white sky albedo = BHR
- black sky albedo = DHR at solar zenith
- The roujean kernel BRDF does not seem to cater for hot spots so you need another kernel for this
- Std Kernel brdf does not cater for different land cover behaviours.  The more detail you have in your imagery, the more detail you require in your correction.  
- Does BRDF actually use a few images at different viewing geom to fit a separate kernel BRDF per pixel?  And not 1 kernel BRDF per scene as I have been thinking???  Per pixel may work for MODIS but geometric accuracy would make it a real problem for aerial images (i.e. pixels over many images would not match up v well) "Thus a successful kernel model usually comprises some linear combination of fixed kernel shapes weighted for each spectral band for each sun-sensor geometry for each surface type."  
- "Here we describe an alternative approach to BRDF correction, called the BRDF Reference Method that uses a satellite image to help generate an appropriate BRDF model. There is no requirement for scene classification and the final product preserves the spatial and spectral integrity of the airborne data. The basis of the referencing method uses concurrent, spectrally-similar satellite data as a reference image to the airborne data, from which a pixel-based model of scene brightness variation can be generated."
- If it is assumed the cover is uniform then there should be one BRDF model per image band.  One needs measurements at multiple angles to fit a BRDF model.  These angles could come from the pixels in one image rather than from mutliple views of the same pixels over time at different angles.  According to me, this is how 
- NB: In cross calib when simulating the TOA refl for the source sensor: (1) The ref DN are converted to surface refl using 6S.  This will be for a certain viewing geom.  The surface refl for the src sensor should then be found with the src viewing geom.  This ideally should involve a BRDF and not assume lambertian.  Then 6S used to xform surface refl to src TOA refl.
- How do they eval the accuracy of a cross calibration?  One way would be with known ground reflectance but then they could do a vicarious calib and I dont think this is done in any of the papers.  They often simulate sensor responses using typical surface spectra and RTM code.  This shows the uncalib relation and gives a good idea if calib will work.  A way to test would be to xcalib then take a later eg image from both sensors.  find the 2 surface refl and compare.  

x- 2016 
- There are many approaches of what is calib to what.  
  - Std XCalib and some UAV calib papers calibrate sensor DN to TOA radiance (calc from ground meas refl converted to TOA with RTM like 6S).  This makes the calib independent of atmospheric conditions i.e. can be applied to any scene.  But the atcor would still need to be applied per scene to get surf refl.  This assumes you have good atcor.  
  - Some other UAV calib and my XCalib, calib sensor DN to surf refl directly.  This includes atmospheric and time of day etc effects and thus is likely not valid for other conditions.  In my case this is ok as the calib must happen for every scene.  
  


Resampling (for X Calib)
------------------------
- Downsampling with cubic or bilinear is not recommended as it is not doing any sort of averaging but is still interpolating between some (I assume) central HR pixels inside the low res pixel.
- Downsampling with average or cubicspline produces similar but not identical results. 
- Upsampling with bilinear and cubic produces similar results that are quite different to cubicspline.  Cubicspline upsampling is smoother and I think the peaks are of lower height.  This is a little strange, one would expect the cubic spline to pass through the orig values at some pt but seemingly it doesn't.  
- I think the theoretical difference between cubic and cubic spline interp is that the cubic spline interp has conditions for the continuity of the the splines like continuous 1st and 2nd derivatives.  This is desirable for us a we expect the real fn is continuous and we are trying to get rid of discontinuities in the mosaic.
- When upsampling in xcalib, there is some extrap as opposed to interp beyond the orig ds edge pixels.  These extrap vals do not match up exactly between images!
- Interpolation can be formulated as a convolution of a kernel with a signal similar to kernel density estimate
- Interpolation is also interesting to consider in the freq domain as a lpr filtering operation, one want an ideal square lpf.  The freq response of the different kernels tells you how close they are to this ideal response.  
- Interpolation seems only (mostly) to be considered as an upsampling operation.  Best methods of downsampling are not generally discussed.
- http://www.ldv.ei.tum.de/uploads/media/Vorlesung_3.4_Resampling.pdf is a good summary and is in Mendeley

- Note cubicspline resampling is not invertible but bilinear and bicubic are (see test res in G:\MSc GeoInformatics\Data\NGI\My Rectified\Resampling).  Eg a ds image A is upsampled with cubic spline to B and then re-ds to orig res C.  A and C are not the same.  Most ds except cubicspline and average, just takes the central pixel val so that is obviously noisy.  For a cubicspline upsampling to be invertible, the average over the block of upsampled pixels matching the ds pixels would need to be equal to the ds pixel val.  But there are other constraints for determining the us pixels such as continiuty of deriv and fitting of splines through/near the ds val.  The more repetitive us/ds you do with cubicspline, the smoother the ds image becomes.  
- If we want the ds xcalib images to match MODIS then we would like "invertible resampling" i.e. A=C in above eg so from this perspective bilinear / bicubic are desirable.  But we also want smoothness (MODIS pixels are noisy - it is maybe not best aim to have xcalib ds == MODIS but perhaps xcalib ds == MODIS with smoothness constraint).  In  terms of smoothness, us cubicspline is much smoother than bilinear or bicubic.  Ultimately it is the us res we are worried about so perhaps cubicspline is still the best option.
- We should look at the actual error of ds xcalib images against MODIS (how about the mosaic used for SPOT?)


PSF
---
- "The degree of spreading (blurring) of the point object is a measure for the quality of an imaging system. In non-coherent imaging systems such as fluorescent microscopes, telescopes or optical microscopes, the image formation process is linear in power and described by linear system theory. This means that when two objects A and B are imaged simultaneously, the result is equal to the sum of the independently imaged objects. In other words: the imaging of A is unaffected by the imaging of B and vice versa, owing to the non-interacting property of photons. The image of a complex object can then be seen as a convolution of the true object and the PSF. However, when the detected light is coherent, image formation is linear in the complex field. Recording the intensity image then can lead to cancellations or other non-linear effects."
- By virtue of the linearity property of optical imaging systems: Image(Object1 + Object2) = Image(Object1) + Image(Object2)
- The images of the individual object-plane impulse functions are called point spread functions, reflecting the fact that a mathematical point of light in the object plane is spread out to form a finite area in the image plane.
- When the object is divided into discrete point objects of varying intensity, the image is computed as a sum of the PSF of each point. As the PSF is typically determined entirely by the imaging system (that is, microscope or telescope), the entire image can be described by knowing the optical properties of the system. This process is usually formulated by a convolution equation. In microscope image processing and astronomy, knowing the PSF of the measuring device is very important for restoring the (original) image with deconvolution.

Mendeley
------------
- Imported pdfs often dont get the details right.  To get around this (1) input the DOI (get from scopus) then use the search button (2) use web importer "save to mendeley" button from eg scopus then merge the docs in mendeley desktop
- The Mendeley csl editor is buggy.  Use http://editor.citationstyles.org/visualEditor/.  CSL files go in C:\Users\harrisd\AppData\Local\Mendeley Ltd\Mendeley Desktop\citationStyles-1.0
- See notes in mendeley pdf "REQUIREMENTS AND GUIDELINES FOR RESEARCH REPORTING" for how to input data for different ref types.  


Tassel Cap
-----------
- A linear xform originally designed for agricultural wheat classification.  It is intended to assist in reducing variability in soil/wheat classes by removing variation due to slope/sun angle & wheat growth stage.
- http://www.sjsu.edu/faculty/watkins/tassel.htm 
- It is a linear combination of RGBIR and as such is related to PCA or fisherm which may produce similar results.
- It realigns rgb data onto a new set of orthogonal axes that are aligned to (un)interesting features in the data such as soil variation, wheat yellowness etc
- Its usefulness should come primarily as a dimensionality reduction technique similar to PCA rather than as improving separability.  For a classifier with sufficient complexity (eg qdc) and enough training objects, it shouldn't matter if pca or tassel cap has been applied as all it does is rotate the feature space.  It is only if you need to reduce the number of features that tassel cap would be useful.

Working with polygons
----------------------
- File geodatabases significantly outperform shapefiles for operations involving attributes and allow scaling of dataset size limits way beyond those of shapefiles. 
- Vector data can be stored in a file geodatabase in a compressed, read-only format that reduces storage requirements. Compression reduces the geodatabase’s overall footprint on disk without reducing the performance.
- File geodatabases can be shared as is (i.e. as the folder structure they are stored in).
- There is an extra GDAL module for supporting file geodatabases so it is not ArcMap specific
- KML/GML ??

Dissertation
- First person: On the other hand, The Scientist’s Handbook for Writing Papers and Dissertations argues that in using the third person, the writer conveys that anyone else considering the same evidence would come to the same conclusion. The first person should be reserved for stating personal opinions.  For example, use it when stating a nonstandard assumption (“Unlike Day and Gastel, I assumed that…”). Or use it when explaining a personal action or observation (“We decided not to include…”).

Abstract, conclusion
---------------------
A1: In the context of a journal article, thesis etc., the abstract should provide a brief summary of each of the main parts of the article, Introduction, methods, results and discussion. In the words of Houghton (1975): "An abstract can be defined as a summary of the information in a document". The "Conclusions" (in some cases also called a Summary) chapter is a summary of the main ideas that come out from the discussion (e.g., Katz, 2009) and hence only a subset of the abstract. Usually the Conclusions sum up the discussion whereas the abstract only reiterates the most important of the conclusions.

-The abstract is written for the potentially interested reader. While writing it, keep in mind that most readers read the abstract before they read the paper (sounds obvious, but many abstracts read like the authors did not consider this). The abstract should give an impression what the paper will be about. Do not use jargon or any abbreviations here. It should be understandable for non-specialists and even for people from fields somehow far away.
-The conclusion should conclude the paper. Keep in mind that the most readers have read the paper, when they read the conclusion. Again, this sound obvious but, again, a lot of conclusion do not read like this. It does not make sense to write a conclusion like "we have shown this and that by using this and that method". Well, this is what the read has just read. A proper conclusion should tell the reader what she can or could do with the newly acquired knowledge. Answer the question "So what?".

- 1. State the problem 2. Say why it's an interesting problem 3. Say what your solution achieves 4. Say what follows from your solution


Feature selection
------------------
- Redundant feats create possible numerical conditioning issues.
- FS should select non-redundant features but must test on independant data otherwise over fitting.  Also is obviously not optimal so once a non-optimal feature is selected things can go downhill.
- While FS may in theory be OK, it doesn't allow handpicking fast features which my method does.
- BB should avoid redundancy but computation time and memory issues.
- BE is dodgy I think for a couple of reasons.  (1) Curse of dimensionality i.e. starting will all features means you are probably overfitting already as you don't have enough training data (2) When there are many redundant features that need to be eliminated, eliminating any 1 of them does not actually improve things
- What about random forests and DTA (CART)

Entropy
--------
- We need to make sure that the feature we are finding entropy for is scaled 0 - 1 so we maximise the histogram resolution

Local Binary Patterns
---------------------
- I dont think I have been using these features correctly, with P=4, there are only 16 possible patterns which seems very quantised.  Also, it is inherently a not so continuous feature i.e. pattern N and pattern N+1 are not necessarily that similar esp with low P.  ALSO: the bit significance in the binary pattern is purely for coding the position, it does not represent the significance of the pattern.  
- Thats why they use a histogram of the patterns with some distance measure (like chi2) as opposed to the actual patterns themselves.
- I think the way I have used it is dead wrong.  It can also only be used as a feature of a region where there is enough data to make a repr histogram.  
- The fact the LBP feature is a histogram makes it a little tricky to combine with other features.  Some kind of clfr combination is probably required.
 
TO DO
------
- Copy over images containing GT areas (the rectified ims pre X calib so that I can try different X calib on them)
- Try improve x calib proc time.  64bit?? + larger cache, tile size??, multi threading??
- Neaten code + provide decent command line args
- Compare raw + x calib mosaic
- Compare basic atcor, with brdf to NGI
- Compare spot to modis
- Find similar bands / pan to compare and see difference

- Est relationship betw MODIS BRDF and SPOT
- Summarise the theory of MODIS NBAR X calib, SPOT validation



CLASSIFICATION
-----------

To Do
-----------
- The fact that calibrated NGI matches un BRDF corrected SPOT suggests calibrated NGI could use some BRDF.  Is there evidence for this in the data eg if we include only N slopes, do we get less variation.
-x Can we expect the other satellite to have better BRDF than MODIS?
-x Is there evidence for tree colours to be correlated with habitat type
-x Is there evidence for tree colours to be correlated with slope orientation
- Why are normalised colours not preferred in feature selection.  If calibration has worked and spekboom colour is consistent, this shouldn't be the case
- How can we incorporate spatial info to better describe trees or better distinguish trees from sb & bg
-x Why is that normalised features do well to separate sb and bg but not trees?  What features separate sb and trees the best?
-x Spekboom looks pretty Gaussian - how about an OCC?  Better performance here will more easily be noticed by running on the actual images than on the extracted data.  How does OCC bdnry look compared to MCC?
-x There are 10 different habitats supporting Spekboom under 2 main headings "Valley" and "Arid".  Can we see systemic differences in bg veg based on these habitat types?

-x Look at per object GT results
-x Try PCA of rgG.  
-x Is rgbnir*pca*qdc the same as rgbnir*qdc ? yes
- Does a bigger texture win help?
- SIFT etc
-x GLCM over objects

-x Tassel cap investigation
- Is my method of intensity norm theoretically valid under arbitrary scaling of bands??

- Be aware of windowed feature behaviour in vicinity of object boundaries
- How can ground truthing best be done to facilitate texture feature extraction
- Include slope and aspect as features (need tons more gt that captures variation in these feats).  To get a feel for this, we could do a test with only N slope feats and compare to all slope results (thing is its v difficult to label gt on S slope).
- Compare random forests, SVM and more basic classifier on both my and jan vlok gt.
- Classifier combination eg separate N and S slope.  Or 1st an OCC that gets all green veg, then a MC that separates sb from veg (BUT the issue is really separating "trees" from sb and bg, not sb from bg).
- What is the inherent number of feats req'd
- SIFT etc
- How well does eCog segment my images
- Convert MISR proj in ENVI or whatever
- Is there evidence for the benefit of using different feature spaces to separate different classes?  (visual inspection of feature scatters, tree / random forest approaches)
- Investigate ways of deemphasising the importance of separating trees and bg (like making them into one class).
- Look at ROC's of sb vs bg.  This is the best clfr eval.

- Use LBP histograms as an entity in a clfr eg use dissimilarity approach (together with rgG ??) or just knnc. 

- Find decent clfr's (with/without texture, svc/randomforest/qdc, occ/mc)
- Can weighting clfr's improve perfomance? - look at 2 class ROC
-x Check the params of svc rbf & librandomforestc ...
- Try dissimilarity approach (see fdsc)
- Possible contextual features: trees have shadows, sb clumps dont.  Or do they?
- Pc2 texture feats
- Smooth per pixel clf output using spatm + combiner
- Gabor filter texture feats??
- There are some built in image feat ex routines in prtools - check them out http://37steps.com/prhtml/prtools.html
- Make a second version of GT based purely on the images (with Jan Vlok???)

- perhaps CIELAB is better than rgG, perceptual uniformity has advantages for distance calc

Observations
------------
- While classes separated by area still overlap, it is possible the distr are quite different
- As above for habitat and possibly more so
- Not only are N and S slopes good predictors but geology too.
- Bear in mind that there are many sources of variation, not just habitat.  There is degradation too which will likely have a greater impact than habitat in some circumstances.
- Looking at the images there is no obvious difference in bg veg between arid and valley thickets + spekboom
- I can notice systematic differences betw valley / arid+fynbos (rougher/spareser - more isolated shrubs) in the Rooiberg image.  Not sure if this is just a local effect?
- The mean error for per area clfrs is much the same as the mean error for an all area clfr !!!

- Feature selection almost always chooses texture or sliding win stats even though they don't look great in the scatter
- This changes a lot with feat sel alg and criterion used This suggests there is something in the texture even though it doesn't scatter nicely
 For some (elusive) combinations of feature and per object clfr, the performance is very good and significantly (~2x) better than per-pixel.  I would be careful about reading too much into this though, there are many feats and  few objects!
- Bear in mind that crossval is important with such a small dataset otherwise results on a single test set give lots of variation.
- In some situations svc or randomforest do better than qdc on per-pixel.  What is interesting in these circumstances is that trees are heavily confused with background but less so with sb.  This warrants further invesatigation.
- In some situations randomforest does better than svc and perhaps qdc on per-object.  The best features for these classifiers is not however found with featself([], <clfr of interest>).  Results vary a lot based on what features are used.  I also suspect that that the class weighting / priors are having an effect.  We should look at ROC's.  QDC does very well however!!
- When feature selection is done with knnc (which should be more closely related to basic separability rather than a specific density form) no texture features are selected although mean over area features are.  meanNDVI, meanGN, meanPc1, bN, tc2 are selected.  The overall results using knnc on 1/10th of per pixel data are good 0.069% which compares pretty well with per-object perfomance.
- ***When doing feature selection with redundant / correlated features on heavily overlapping problem, results can appear somewhat random as no particular feature makes a big difference & many are similar to each other.
- Principal components, tasseled cap and PCA(rgG) are clearly related from plotsig.  Probably TC is best separated then PC.  
- Feat selection
	- The best FS procedure that I've seen is a manual process of clustering features based on correlation, ranking features based on individual performance, ranking clusters as the mean of the features they contain, then choosing a feature from each of the best N clusters.  librandomforestc gives best results on these features.
	- Good per-pixel classification  performance on dataset does not correlate that well with good canopy cover performance on jv gt.  Performance on jv gt doesn't actually vary much but there seems to be an inverse rel betw accuracy on jv gt and the per-pixel dataset.
	- featselo run on small data sets returns correlated features (fitting to noise?)
	- featself([], nn/naivebc/qdc) returns features from different feature clusters but some features come from poorly ranked clusters and sometimes it chooses correlated features i.e. from same cluster
	- featself mostly chooses at least one feature from the 2 best clusters
	- wfso = featself(subData, libsvc([], proxm([], 'r', 2), 20), 6); selects features from different clusters although not the 6 best clusters.  Performance is v good on these feats too and similar to the ranked cluster approach. Only problem is it uses sliding win features.
- dd routines need to be used with caution.  there are often conditioning issues, inappropriate default params etc
- Comparing 3 class qdc, 2 class qdc and gauss_dd (2 class): The 3 class performs best as expected (as it is effectively a MOG for 2 class).  2 class qdc and gauss_dd are v similar after a bit of fiddling on gauss_dd
- 2 class and 3 class svc are v similar in performance & ROC
- Be careful with EntropyPc1, there seem to be occasional numerical issues.  scalem([], 'variance') can help with this
- Svc dd tools are v slow and not practical to test
- Of the good dataset clfr's, All_Svc_clfr_3class does best on jv gt (compared to random forest and mogc occ).
- SVC is slow to run because of distance calc for RBF, random forest, mogc are reasonable

- Big classifier errors are somewhat explained by visual inspection / canopy cover est of the imagery i.e. perhaps the JV gt is not that accurate or things had changed between 2010 and 2012.  Comparing visual canopy cover est made from the imagery with classifier results gives lower error than comparing jv gt against clfr results.
- Perhaps a case can be made that visual est of canopy cover from photos is a less reliable est of jv gt canopy cover than clfr est of canopy cover.
- Looking at clfr output in jv polygons where clfr errors where high: the errors are understandable and difficult to avoid.  In Matjiesvlei, there is a lot of other green bush, so sb is overestimated.  In rooiberg, the sb colour is weak (perhaps they are smaller as that area is recovering) so sb is underestimated (also I think rooiberg is poorly repr in my training set).  In other situations, the jv gt looks off (eg see 2 notes above) eg groenfontein4.
- It seems fair to say that a balanced classifier should produce ~0 mean canopy cover error (on jv gt)
- When training per area classifiers, my training data is not very representative, so I get good per-pixel results and poor jv gt results due to a kind of overtraining or biasing my the poorly repr training data.  The implications of this are: we still don't know if per area is a useful approach as we have not eval it properly i.e. we need better gt.  We need to be careful about what clfr's we use on the training data now that we know it is not that repr.  It would be better to get more gt, memory is an issue for holding it all though.
- Classifier performance is heavily dependant on the gendat data sampling (i.e. it is important to use the same splits when comparing clfr's)
- Given that feature selection is computationally too intensive to run on all data, and than a kind of overtraining occurs on smaller samples of the data, feature selection results are very unstable and vary a lot depending on algorithm & data etc (also due to correlation of features)
- In an attempt to get round this I devised my own heuristic feature selection algortithm.  Features are clustered according to their correlation to each other.  Single feature models are evaluated to rank/score the features in each cluster and then each cluster is given a score based its constituent features.  A feature from the best N clusters is then chosen where N is found using a kind of crossval.  This allows the simplest / fastest features to be selected.

- The DTree clfr that gives best results on JV ground truth canopy covers, visually seems to overestimate spekboom and underestimate trees.  The results are also completely wrong in some areas where no training data was gathered, esp big mountain slopes in N and S.  These dodgy areas are not in sb habitat though and can thus be masked out.  

- Closer inspection of xcalib imagery + clf results does indicate some calib issues.  They don't really match what the algorithm should be doing and need further investigation.  Defects are aligned with MODIS pixels.  In the vicinity of these issues, the classification overest sb quite bad.  The first one of these corresponds to a boundary between jobs eg 3321D_319_01_0027_RGBN_XCALIB and 3321B_3172_12_0422_RGBN_XCALIB.
The second case also coincides with MODIS pixel boundaries.  This second case is not on the boundary of jobs but in an area of deep canyon, specular refl.  There is a significant vartiation in the raw imagery brightness & colour with saturation in this region. Which can explain things.  The calibration defects are more transient from the pixel boundary and them seem to resolve themselves.  Whereas in the first case, there seemed to be a systematic issue between the 2 jobs.
On second look at the first case, the dicrepancies are not that bad.  They are visible in the region of the border, esp at certain MODIS pixels but then seem to resolve further into the image.  I don't think it suggests something systematic is wrong with the images.  The images are from different times of day (and different days) and probably it is BRDF related.  Eg in the early morning the bushes look yellower than they do later while later, the sand looks yellower than it does earlier meaning that the balanced (xcalibed) images dont make the best match.
- There is v little difference in performance on a N Slope only vs All Slope data set.  However the data is biased to N Slope as GT is difficult to label on S Slope.


SVC
---------
- Use [wRbLibSvc, kernel, nu] = rblibsvc(tr(:, feats)*scalem(tr(:, feats), 'variance'));  to get a cross validated est of the rbf width.  (it is ~2 for the feats I checked).  I think if scalem is used it should stay fairly constant irrespective of features used
- libsvc([], proxm([], 'r', 2), 100) (i.e. C=100 and rbf with p = 2) gave the best results from a rough check
- The improvement in libsvc when optimising C & p negligible !
- Using RBF kernel is def better than linear version
- Polynomial kernel does not improve on RBF kernel
- Perfo

Decision trees and Random forests
--------------
- Should be trained on the entire feature set as a "feature selection" is implicit in the training procedure and uncorrelated features are req'd.
- The feature importance can be found as part of the training procedure but it is important to note that this is the importance of an individual feature not the feature in the context of other features.  Strongly correlated features will have strongly correlated importances.  The importance measure for a particular feature is similar to the increase in error one would obtain if one were to remove that feature from eg a KNN classifier i.e. like BE.
- It is not advisable to use this feature ranking for other classifiers.
- see maketree in treec.m for defn of the mapping params.  This contains the selected features in tree(:, 1) although its not clear how exactly they are ranked.  
- Naivebc should give similar performance to treec and could be used in featselo as a substitute for CART.  Also featself with treec should simulate cart I think.
- Stats toolbox classregtree is also an example
- Otimising ntree and mtry for librandomforestc does VERY little to improve performance
- dtc definitely does not appear to give the same results as for randomforestc
- Using only the clustered and ranked feats gives much the same performance as using more/all feats
- decision tree feat sel is the feat used at each node.  it is a greedy / sub optimal search using the tree criterion and as such is not a great feat sel technique for general use with other clfrs
- random forests use bagging of decision tree classifiers with: random feature subset selection for what feat to use at a node and some randomisation of the actual decision made at each node.  it relies on having many uncorrelated trees - more difficult to achieve with correlated features.
- random forest variable importance is measured by "permuting" ie randomly rearranging the values of a specific feature among the test objects and evaluating the out of bag error before and after this.  If the variable is important, screwing with it in this way will have a large impact on the error.  This is still a measure of importance tied to the random forest and not a general measure and is also a measure of each feature in isolation i.e. sub-optimal (correlated features will have similar importances and the 2 best features in isolation are not necessarily the 2 best features in combination).  It is a conceptually similar measure to a single step BE.  
- random forests overcome the problem of overfitting or peaking(?).  this is perhaps similar to svc that adapt complexity to the problem.  this property differentiates them from other classifiers.
- Breiman: "Important recent problems, i.e., medical diagnosis and document retrieval, often have the property that there are many input variables, often in the hundreds or thousands, with each one containing only a small amount of information. A single tree classifier will then have accuracy only slightly better than a random choice of class. But combining trees grown using random features can produce improved accuracy"
- out-of-bag error means the error from all trees/clfrs that were not trained with that object
- random forests are robust to noise in outputs i.e. mislabelled training data
- random forests work well for problems with many weak features which are difficult for eg neural nets or trees
- While the CART and random forest feature rankings are for independent features, they are made in the context of other features i.e. not in isolation i.e. with all the other selected features as part of the model.  This should make this ranking less prone to the problem of "the best two features are not the best two" as if a feature is part of a good group, its removal will be noticed.  If it is correlated ind with another feat in the set, its removal wont be noticed though, so correlation is still an issue for these rankings.  

Restoration Projects
------------------------
STRP
	- The STRP was launched by the Department of Water Affairs and Forestry (now DWA) in January 2004 and falls under the DWA/Working for Woodlands Programme, with funding provided by the government’s Expanded Public Works Programme (EPWP). The implementing agency is the Gamtoos Irrigation Board (GIB) which deals with day-to-day management. Through the programme, large areas of the native Spekboom have been planted to capture carbon dioxide (CO2) from the atmosphere and sequester it in the plant biomass, litter and soil. PRESENCE supports STRP as an engagement platform for all stakeholders and researchers from national and international universities. Additionally, Living Lands supports STRP with stakeholder engagement and raising awareness
	- By August 2011, over 2,600 hectares of the Eastern Cape had been planted under this programme, providing employment for hundreds of people.
	Thicket-wide experimental plots have been established across the breadth of the biome, monitoring the effectiveness of different planting methods in re-establishing thicket.
	-In September 2011, the Addo Elephant National Park, Baviaanskloof Nature Reserve and Great Fish River Nature Reserve Restoration Project (ABFRP) was launched as a sub-component of the STRP.
	-Validated under both the Verified Carbon Standard and the Climate, Community and Biodiversity Alliance, this project will run for the next sixty years, earning carbon credits and restoring the natural vegetation of three iconic nature reserves in the Eastern Cape. (? this doesn't tie up with what MP said)
	- Mills++ involved
R3G
	- comprises a small team of scientists who provide advice on the most cost-effective interventions for restoring degraded ecosystems, while ensuring opportunities for social up-liftment. 
	- R3G’s primary partners are the Working for Water and Working for Woodlands Programmes. 
	- R3G provides scientific advice to an implementing agency, namely the Gamtoos Irrigation Board (GIB) based in Patensie.
	- R3G scientists are associated with the Nelson Mandela Metropolitan University and Stellenbosch University 
	- (Sigwela, Mills & Cowling)
	- "The culmination of years of rigorous scientific research by R3G and extensive field trials supported by the NRMP has been the validation of the project according to the Verified Carbon Standard (VCS). VCS validation will allow the project to enter the voluntary carbon market and earn carbon credits which can be used for further restoration. In addition, the project has also received validation under the Climate, Community and Biodiversity Alliance’s (CCB) standards that certify the project for carbon sequestration, as well as positive community benefits and the conservation of biodiversity. The validated project is known as the Addo Elephant National Park, Baviaanskloof Nature Reserve and Great Fish River Nature Reserve Restoration Project (ABFRP). "
NB See MP's presentation in Mendeley for financials, allometrics etc
Subtropical Thicket Ecosystem Project (STEP)
   - began in 2000 with a four year planning phase supported by the Global Environment Facility (GEF) and implemented by the Terrestrial Ecology Research Unit (TERU) at the Nelson Mandela Metropolitan University. The main aim of the planning phase was to conduct, together with key stakeholders, a thorough conservation planning exercise in South Africa's Thicket Biome.  

Notes on BMR Carbon Stock (esp budget)
---------------------------------------
- Worldview-2 geometric accuracy is at best <2m
- Quickbird etc have swath width ~16km
- MP's 40 plots lie in ~40km W-E width and 10km N-S height
- There is a rough suggestion looking at Google Earth that carbon stocks are correlated with greenness
- Also include gt field trip, hard drive, student fees + time

Q for Adriaan etc
--------------
- Can I supply Andrew Knipe with my thesis? (IP remains property of SU?)
- IP of PhD
- How much do I have left to do?
- I should check with JV and AK that they are OK with me withdrawing from m and doing p.
- I should check with JV what other ideas he has, what extra gt he has?
- Reap MP's thesis
- New Arcmap
- What are phd req, how much work




Results
--------

Notes on feature Images
------------------------
- rN and gN look useful.  Both have green plants as darker than surrounds (I guess the ground is greener than the plants?1).  They are quite sharp/textured and slope/topography independent.
- bN is interesting.  The topography appears inverted (i.e. shady slopes are bright and vice versa) and bN is very much topography dependent.  Relooking at the RGB images does show that shaded areas are purplish.  This is likely because in the non-direct sunlight (shaded) areas, scattered light is the dominant means of illumination and scattered light is blue biased for the same reason the sky is blue (blue scatters more readily than other colours).  This suggests that Blue is suspect in general and should possibly be ignored entirely from all analyses (colour normalisation, PCA etc).
- NDVI is topography independent and a good indication of veg greenness as expected.  It is quite smooth/blurry/untextured likely due to NIR also being blurry (wavelength physics again?).
- TC1 looks like intensity.  Topography dependent, little/no colour info.  Sharp/textured.
- TC2 is quite interesting.  It is dark and smooth where things are greenest, otherwise intensity-like, topography dependent.  Not sure if its too useful though.
- entropyPc1 somehow manages to pick up a grid inside of one image??? Some artifact from the sensor???  Interesting in that it is uncorrelated with spectral features.  It definitely picks out smooth areas.
- stdPc1, also picks out the grid above.  Tends to delineate objects incl bushes but less so bush clumps.  May be useful for segmentation.  Does not look good for per-pixel classification.
- lbpPc1 looks quite noisy.  It doesn't seem to help distinguish SpekBoom.


Notes on Habitats
------------------

Valley Thicket with Spekboom
----------------------------
In this habitat type the Thicket vegetation occurs in extensive stands with Spekboom (Portulacaria afra) prominent. This habitat is most easily recognized by having Pruimbome (Pappea capensis) relatively abundant which, like most of the other trees present, often occur as fairly large single trees that are not restricted to bush-clumps.

Valley Thicket with Spekboom Mosaics
-------------------------------------
This habitat type differs from the Valley Thicket with Spekboom habitat type in having the Thicket vegetation present occurring as fragmented patches. Spekboom is also present, but often not abundant, but Pruimbome (Pappea capensis) remains prominent in the Thicket patches that can occur in a matrix of Succulent Karoo, Renosterveld, Sandolien or Fynbos vegetation. In areas with a broken topography the Thicket patches are often restricted to north-facing slopes, with the vegetation present on the south facing slopes depending on the local geology. On shale it is Succulent Karoo or Renosterveld, while quartzitic areas will have Sandolienveld or Fynbos on the southern slopes. The species present in the Valley Thicket patches vary little, but those that are present in the matrix vegetation can vary dramatically in sites where the geology is complex..

Arid Thicket with Spekboom 
---------------------------
It differs mostly from the Valley Thicket with Spekboom habitat types in lacking Pruimbome (Pappea capensis), but Gwarrie (Euclea undulata), Pendoring (Gloveria integrifolia) and Koeniebos (Rhus undulata) are prominent trees. Noorsdoring (Euphorbia coerulescens) is sometimes abundant and where absent, is replaced by other thorny Euphorbia species such as Euphorbia atrispina and Euphorbia heptagona. A rich variety of succulent species is usually present, but grasses are uncommon.
This habitat occurs mostly on northern slopes of hills and mountains. It is vulnerable to the impacts of grazing as is not able to recover easily from heavy grazing pressure

Arid Thicket with Spekboom Mosaics 
------------------------------------
This habitat differs from the Arid Thicket with Spekboom habitat in having fragmented patches of Thicket occurring in a matrix of Succulent Karoo and/or Renosterveld. The general structure of the vegetation in this habitat remains very similar, but the species in the matrix vegetation changes much with variance in soil conditions and rainfall. Quite a large number of vegetation units (26 units) have thus been identified to occur in this habitat type. Several localized endemic plant species occur in the matrix Succulent Karoo or Renosterveld vegetation of this habitat type. The combination of Thicket, Spekboom and other vegetation renders it an ideal for grazing purposes



Notes on Drones
---------------
- Orthorect SW
  - Generally does not seem to require attitude/orientation - only GPS position.  Or does orientation come from drone auto pilot?  What about DGPS?
  - Actually, the gimbal likely uses orientation from gyroscopes to remain in position.  
  - can make nice dems.  where does altitude and orientation data come from though?
  - Then GCP's are needed using a base layer map like google maps.  
  - Possible rectification software PTGui Pro, PhotoScan, AutoPanoGiga, and DroneMapper but reports of difficulties
  - Also Pix4D (commercial) looks good.  USD 350 pm or educational license?  Pix4Dmapper for flight planning with DJI Phantom drones.  
  - Maps made easy: sub-decimetre gsds, sw as service, good reviews.
- Gimbals
  - Req'd to orientate and keep camera steady
  - Can be electrically driven by motors to stay in pos using an MRU with gyroscopes
  - Old school gimbals just used gravity eg with ships compass to keep it horizontal 
  - "the Inertial Measurement Unit (IMU) is equipped with three orthogonally mounted gyros to sense rotation about all axes in three-dimensional space. The gyro outputs are kept to a null through drive motors on each gimbal axis, to maintain the orientation of the IMU."
  - DJI makes gimbals for various cameras.  It seems like the gimbals are camera specific - weight / centre of gravity related / form?  Actually the z15 works for different cameras.  ±0.05° accuracy.
  x- Gimbals are probably more necessary for continuous filming than multiple stills ??
- NIR
  - Eg on MapsMadeEasy of "Canon PowerShot S100 modified with an Event38 filter" but this has no red channel 
  - In general rgb cams are modified by replacing a vis filter with a vis-nir filter or similar which means, the read channel becomes red+nir. This seems suspect as it is really the red edge that is interseting for vegetation which will be lost with this approach.  This is confirmed by http://agribotix.com/blog/2014/6/10/misconceptions-about-uav-collected-ndvi-imagery-and-the-agribotix-experience-in-ground-truthing-these-images-for-agriculture
  - "There is a reason that TetraCam and MicaSense cameras cost multiple thousands of dollars. These cameras are properly built to collect data that is sufficient for comparative spectral analysis. Throwing a blue filter in front of a normal Bayer pattern sensor and removing the IR blocking filter is not enough."
  - Tetracam make suitable Nir,R,G cams - their cheapest cam is 3000 USD
  - MicaSense make multi-spec cameras eg RedEdge is available for USD $6,450, Bands: Blue, Green, Red, Red Edge, Near-Infrared ! 
  - Veg blows in the wind - mosiaced/rect sub decimetre res of veg can look weird
  - see http://community.dronesmadeeasy.com/discussion/comment/129/#Comment_129 
  - 2 cams a possibility, obviously wont register fantastically
  - See PublicLab’s NIR
  - "Looks like we've got pretty similar setups. I started flying my skywalker with two cameras so I could create a four-band image. Shadows are pretty much the enemy in my mind, so I fly both cameras at the same time to keep the images as consistent as possible. I made a couple pods out of foam core board and mounted them to the fuselage on some metal rods that I installed just below the wing mount."
  - See eg of 2 cams on 1 GoPro gimbal here!!! http://diydrones.com/profiles/blogs/ir-and-eoi-brushless-gimbal 
- Issues compared to satellite
  - Radiometric camera calib
  - NIR + other bands
  - Range & repeatibility vs cost i.e. is it really cheaper?
  - VVHR image processing - shadows, data vols
  - Surveys over long periods as compared to satellite, which means varying lighting.  Really?  - phantom only has 20min flying time...
  - Practically, given that aerial surveys take days to complete, how long will it take with a 20min flying time drone with limited range.  
  - Legal issues - 500m, altitude. 
  - Possibility for DEM is great though and could be v useful with carbon stock estimation
My Notes & Questions
  - Lit survey of veg anal with drones: yes - using dem for forest canopy and rgb for algal mapping 
  - General recommended cameras: ""I would say that the best and easiest stitching results we get are from the Sony NEX line and the Canon G15. The images are beautiful and the geotags tend to be pretty spot on. The results are always really nice. For a cheaper visible camera, the point and shoot cameras that geotag such as the Canon S90, S110, SX230 and SX260 have done a good job and support the periodic imaging functions nicely.""
  - quadcopters can fly low and slow and thus get ++res 
  - See also  diydrones.com and conservation drones \
  - What is a good way to get NIR - can 2 cams be used & then registered or even 2 separate flights?
- DJI Phantom
  - More made for film than survey 
  - 15000-20000 incl camera and gimbal 
  - Incl GPS/GLONASS and probably the IMU of the gimbal 
  - <25mins flight time 
  - Angular Vibration Range ±0.02°
  - Max wifi xmission dist: 500m std / 2000m advanced 
- Conservation Drones
  - 
- The LAW
  - Can fly up to the height of the highest object in 300m of the drone (up to a max of 400 feet).
  - Can fly up to 500m away from the pilot, while maintaining direct line of sight (RVLOS).
  - http://droneworld.co.za/commercial-regulations/

Notes for WWF meeting:
----------------------
- Any imagery still requires calibration, this is not some defect specific to NGI 
- Actual classification/regression algorithm is not strongly correlated to imagery i.e. same techniques could be applied to satellite/ aerial/ uav imagery assuming decent calibration and similar spectral content.
- UAV's
   - 3D models, revisit rates, spatial res, cost are benefits 
   - Probable lack of need to atcor is also a plus
   - But there are limitations and risks, use of uav's for rs is in its infancy.  Its easy to make flashy website + youtube videos.  To make something work reliably in practice usually requires a lot of work, overcoming (often unseen) obstacles.  80/20.
   - No affordable scientific grade multi-spectral camera
   - Radiometric calib issues are potentially worse due to shadow variations and details, ots cameras and are as not solved in std way
   - Cost potentially rises quite sharply with coverage (separate missions and ground co-ordination + manual processing) as opposed to satellite so there may be a pt on cost/coverage curve where it becomes more economical to use satellite. Cost of satellite will obviously have to compete with UAV.
   - Dont forget processing (orthrect) costs which are time-consuming manual ops but are incl in satellite imagery (usually)
   - Legal issues 
   - No historical imagery which could be issue depending on if ground truthing was done destructively
- Automation concerns:
  - Steps requiring manual interventions
	- Sourcing imagery + ref image 
    - Orthorect (depending on image src - not necessary for NGI or satellite)
	- Calib validation
	- Ground truthing 
	- Possible canopy cover classifier retraining would require image ground truthing.  
	- Possible carbon stock refitting would require representative field ground truth.  
	- The actual model or classifier and software tools and procedure would not need to change but there will likely be some manual steps.
	- These manual steps would really be reqd by any approach and are not limited to my approach.
- 3D DEM
    - Data is more repeatable than spectral data as it is not subject to lighting / phenological variations.  Would be great to use.  
- PhD vs Implementation
	- I'm close to PhD and I'd like to get that out the way.  
	- It is research and implementation only makes sense if I get something to work...
	- I'm keen to be further involved though and could assist in further validation and producing end-user tools.
	- What are your expectations as to outputs?
	- Could separate into 2 sections
- My costs
    - Imagery ~35000
	- Field trip(s) 5000
	- Data storage 2000
	- Commercial AUV software processing pix4d 350USDpm~ R5000 
	- AUV 20000
	- R42000 + R25000 (auv related) = R67000
- What is more important canopy cover or carbon stock - cc can be fairly easily ground truthed visually on ims or field.  cs obvioulsy lot harder which makes data repr issues 
- Rehearse presentation, reread thesis (&MP's thesis), know my accuracy figures + limitations.
   - Tree class, fine tuning clfr, more diagnostic info, cheap clfr complexity, 
   - Per-pixel: little spectral mixing, simpler is better and object based approach is poorly-posed/ fiddly/ req expensive sw 
   - Fortunate that imagery in Jan, over short period with matching MODIS and SPOT 
   - per-pixel and sliding win features to exploit VHR spatial info, some texture feats ommitted because they need large contiguous regions  
   - entropy, 
   - post proc morphology to close holes, remove thin sections is also exploiting spatial info 
   - "Inspecting bN images shows an inversion of the topography shading seen in other channels.  Sunlit northern slopes are dimmer and shaded southern slopes brighter.  This occurs because in the shaded areas, the blue light, which scatters more readily, is the dominant band of illumination.  The contribution of bN is not understood fully but we believe its value lies in this property and that it helps distinguish shaded vegetation from genuinely dark vegetation.  "
   - Features and clfr chosen for computation time (feature ranking and clustering useful for this!)
   - Good perf of diverse clfr means good feats that sep classes well
   - Ground truth biases (easy classes on images)
   - Know the error terminology
   - "Arid areas seem somewhat prone to underestimation, possibly due to spectral mixing occurring with bare ground around the canopy borders and also due to the smaller and less dense plants occurring in these areas.  Conversely, there seems to be a slight overestimation in more densely vegetated areas.  Confusion due to spectral mixing with other green vegetation seems the likely cause"
   - "While some variation in the classification accuracy was observed with habitat, the classifier was remarkably robust to the many sources of variation that make this a challenging problem. "
   - Possibilities to improve by incl slope aspect as feat or per habitat clfr
- WolrdView-2
   - 3 bands in nir as opposed to 1.  I don't see any std radiometrically corrected products.  300/km2 for orthorect and 200/km2 for georef.  
   - Using "scientific" and est source of imagery would help reduce unknowns and answer some important research q's like does it help having extra bands in NIR region.  But this can just be for research - depending on results, implementation can then use UAV.  
   - "Radiometric calibration" can refer to calibrating purely for sensor spectral characteristics eg non-lin, spatial non-uniformity.  Then also for calibrating out illum source's (i.e. the sun) spectrum.  Ultimately we want surf refl which req's correction for atmospheric and brdf effects. 
   - From GeoData: R324.28 per km² for the WorldView-2, 8 Band, 40cm imagery ortho-ready 
   - from Landview: $20 per km2 for 8band 
   - From Landview: The minimum order area for archive imagery, for all sensors, is 25 sq. km with a 2km (DigitalGlobe) or 3km (GeoEye)
					minimum order width.
					To receive archive pricing, QB,WV2,WV1, GE1 & IK imagery has to be older than 90 days in archive.
					No hold on Pléiades imagery.
   - My email: According to this supplier there is no archived Worldview-3 imagery of the Baviaanskloof which limits us to Worldview-2 unless we want "new tasking" where they will capture that area    specifically for us (for more money of course).  They also say that the 0.4m image pixel size provides very little improvement over the 0.5m pixel size as the actual sensor pixel size is ~0.46m.  So I have opted for Worldview-2 0.5m imagery in this budget.
   - From LandInfo: "We schedule a new collection but the cost goes up to $39 per sq. km."
	- How big is one image, how does orthorect actually work per image?  how much work would be required per image?  would it be accurate?
   - Swath Width	16.4 kilometers at nadir	
   - Orbit Altitude	770 kilometers
   - Accessible Ground Swath Nominally +/-40° off-nadir = 1355 km wide swath
   - So my Baviaans study area is covered by 3-4 scenes 
- Custom NIR Drone
   - From Tudor at donesmadeasy: "We are going to build a system to carry two cameras that is based on the DJI Matrice 100. It will have a real NDVI camera and a normal visible camera. The best way to get dual data sets like this registered is to do the visible first and then use the visible layer to do a basemap georeferencing with the IR data. Two flights works too, it just takes longer. Generally, people seem to be able to get them to align within an inch or two as long as the images give a good reconstruction. "
   - ditto: "TetraCam is really the only thing out there that is fully calibrated. The technology is old and it is a pain to use though. We are starting to evaluate the Sentera cameras but suspect that they will have the same issues. They are quite a bit cheaper though and seem to be better than most of the stuff out there. "
   - from Alyssa at MicaSense: "We caution against integrating with the Phantom family, as it has a small payload capacity; we have found that generally any gimble that you would use, plus the RedEdge, would be to much weight. However, we do have customers who have integrated successfully, we just caution against it as it can cause problems.  Specifically, I believe the Phantom payload must be below 1300g at takeoff. The drone itself is already 1000g, our camera is 163 grams, including the external GPS, giving you less than 150 g for a gimble. Also, as this weight is close to the maximum for the platform, the UAV will not be able to fly as long, and will be more difficult to control.  I do know that other DGI platforms, such as the S series, have more payload capacity. and probably would integrate better with our camera. Please let me know if you have any further questions about this integration; you can also call me if needed."
   - Multispec cams
     - Sentera double (oem), $3,699, 44deg field of view, accepts autopilot gps + metadata, 10MP stills, up to 3fps 720p video @ 30fps*, 2x microSD slots
	 - Sentera single (oem), $1,599–$2,299, 1.2 / 10MP stills, up to 3fps, 720p video @ 30fps*, 44deg field of view, microSD slot, ethernet + serial interfaces, accepts autopilot gps + metadata
	 - Sentera quad (oem), $6,999, actually 6 channels - normal bayer rgb, plus 3 NIR channels, 126gm, 1 32GB card per sensor, 44° HFOV
	 - Sentera Phantom 3 Upgrade – NDVI Crop Health Camera $2,599
	 - Custom - feasible to remove IR stop and put IR pass filter on normal ccd and get NIR cam? Eg Canon.  Also to make separate flights with different sensors and then match them afterwards i.e. georef one sensor to the other
	 - MicaSense RedEdge, USD $6,450, 5 channels, single sd card, 150gm, Spectral Bands Narrowband filters for Blue, Green, Red, Red Edge, Near-Infrared, GSD 8.0 cm/pixel at 120m (~400 ft) AGL, 1 cap/s 
	 - Tetracam micro-mca, 6 band ms camera, 500gm, http://www.tetracam.com/Products-Micro_MCA.htm, see also paper "SENSOR CORRECTION AND RADIOMETRIC CALIBRATION OF A 6-BAND MULTISPECTRAL IMAGING SENSOR FOR UAV REMOTE SENSING" in Mendeley
	 

- CS Ground truth
   - Check my understanding of ground truth
   - there are 65,50 and 76 plots (180) plots 
   - put the gps locs into google earth and look 
   - 5x5 inner plots are intactish and measured.  Allometric relationships established with plants outside that area?
    "with the 25 m2 and 625 m2 being the outer grid for the DST/ST and OL, respectively. The outer grid was used to employ allometry, within which 4 m2 grids were laid for sampling all herbaceous biomass, and a 0.25 m2 plot was laid out for litter sampling"  the 0.25m2 litter plot is inside the 5x5m plot, what does this actually mean?
   - about how many plants from a species were sampled to est allometry: looks like ~20.  then allometry uses >1 variable or just chooses the best variable? 
   - representivity: 2 issues: 
     - size of plots to get good habitat and pixel averaging
	 - number of plots affects the num of feats that can be used i.e. with ~200 data pts, I think we can only fit with up to 3 vars  (2^10 == 100).  
	 - if plots are bigger we can subdivide into mult subplots to get more data pts.
	 
- CS Ground truth Q for Mike
   - Where was destructive plant sampling done inside or outside of 5x5m?  To establish allometric rels.
   - Where was the allometry applied - inside 5x5m?  Every plant gets its stems etc measured?
   - What other destructive sampling was done inside 5x5m - litter?  herbaceous?
   - There are still stakes there 
   - Were these plots planted?
   - When did this all happen 

	 
  - Results:
    - mean absolute canopy cover error of 5.85% with a standard deviation of 4.65% on the field ground truth
	
-------------------------------------------------------------------------------------------------------------
Orthorectification 2017
- You need the orientation of the satellite and DEM to reverse the pereptive warp caused by terrain and orientation of the satellite
- The rational polynomial model i would guess models things like lens/sensor distortion and perhaps includes orientation 
- Many tools do the above using RPC's and DEM eg GDAL, ArcMap, Orfeo 
- How are GCP's used though: (1) if they are used before DEM perspective correction (for a simple affine xform) then they will have perspective errors and wont match real ground co-ords no matter how good the affine xform.  
  (2) if they are used after DEM perspective correction, they perspective errors will obviously be much less, so an affine xform makes more sense but it is still not right in terms of the geometry as you are then kind of shiting the dem the around.  
  (3) if the gcp's could be somehow used to optimise DEM the perspective xform, this would make sense to do everything in one shot.  is this the bundle adjustment? 
  BUT remember a non dem (linear) perspective xform can account for differing views of the same scene (but only if you know the 3d world co-ords of the scene i.e. the DEM)
  x(4) see (A) below 
-  The geometric accuracy of the DEM is NB, as well as the resolution.   
- "A rational polynomial camera (RPC) model is a kind of generic sensor model that can be used in different remote sensing systems to model the relationship between object space and image space and transform image data to conform to a map projection. "
- The RPCs replace or approxmate the camera model (i.e. internal model?).
- The RPCs seem to include exterior orientation info i.e. they map from 3d world space to 2d camera space.
x - Where do GCP's come in to the orthorect process?  The RPCs describe
- With GCP's accuracy can be tested in a LOO or cross-validation type manner 
- gdalwarp -rpc -to RPC_DEM=srtm.tif raw.tif rectified.tif
(A) This is my best understanding at present: 
    - The RPCs describe map from 3d world to 2d camera co-ords (include camera pos and pose and lens distortion etc).  The DEM decribes the actual world depth / 3d co-ords that would have generated the 2d camera scene.  Using this info (3D surface + camera image + RPC ) and some geometry, we can create an orthographic projection of the scene i.e. as if viewed at nadir from infintity (all // rays).  This is how orthorect without GCPs works.  The RPC model has limited accuracy however, so GCP's can be used to improve this.  Using the provided (inaccurate) RPC, the GCP postion can be found in the 2d image.  Then some cost fn can be made that punishes the error between the projected RPC im GCP positions and the actual (user-detected) GCP positions in the scene.  This cost fn would be used to fit perhaps a supplementary affine model or adjust the exisitng RPCs so that the projected GCP's match with their actual locations.  Then the usual orthorect procedure can take place using the improved (either RPC + afffine or improved RPC) camer -> world model. 
- "This recipe demonstrates how to use GCPs that were previously collected to improve the accuracy of a math model (RPCs), which is then used to orthorectify the imagery"
- "bundle adjustment" seems to refer to correction of overlapping aerials using "tie points" in the overlapping areas. 
- "With  direct  georeferencing  or  RPF  a  high  relative  positioning  accuracy  can  be  achieved  in  most  cases.  Absolute  accuracy  depends  on  the  accuracy  of  the delivered  orientation  metadata.  It can be improved by integration of precise GCP, which are re-trieved,  e.g.,  by  direct  GPS  measurements  in  the  terrain.  When  an orthoimage is available (reference image, e.g., from archive), GCP  can  be  extracted  (automatically  by  image  matching  tech-niques  or  manually)  to  improve  the  absolute accuracy.  If  the  number  of  extracted  points  is  sufficient,  they  can  be  divided  into  GCP  (used  for  improvement  of  the  orthorectification)  and  independent control points (ICP). Analyzing the accuracy of the ICP  after  orthorectification  results  in  an  additional  accuracy  information, which is also of interest to the end user. "
- With a very narrow FOV, nadir satellite is already close to orthographic projection, so perspective distortions due to topogrpahy are much less than for aerial imagery.  This means using a DEM is less important than for aerial imagery - "Satellite sensors have a very narrow field of view (FOV) compared to the airborne so that in principle the effect of  the DEM error on  the produced  orthophotos could be reduced almost to zero if images are collected as close to nadir as possible. However i n practice  the sensors can rotate (flexibility and revisit)  and  most  of the  space  imagery  is  collected with  off-nadir  angle. It  is  therefore  important to ensure  that  the  DEM used  for  the  orthorectification  (existing  or  produced)  will  be  of  sufficient accuracy (Figure 2)."
- RPC is seldom good enough for satellite imagery: "For VHR  imageryorthocorrection  will  be  required  in  most  cases.  Polynomial  correction  with  VHR images  will  only  provide  acceptable  results  only  in a few restricted  circumstances of  flat  terrain.  In practical terms, planning and provision for the orthocorrection will mean that this choice will rarely be made."
- NB see section 3.2 in http://download.xuebalib.com/xuebalib.com.18247.pdf RPCs are corrected/adjusted with an affine xform derived from gcp's (my guess is the affine model is fitted to the RPC transformed image)

Quickbird Orthorect implementation 2017
-----------------------------
-----------------------------
- There are a few options for the RPC + DEM rectification i.e. gdalwarp, Orfeo, Arcmap
- Then gdaltranslate can make a poly/other xform from gcp's.
- Gdaltranslate can also convert from projected co-ords to image pixel location using RPC  
- It should be possible to simply convert from GCP co-ords to pixel location by 
  - getting co-ords in the in the projection of the image 
  - Obtaining the image co-ordinate extents 
  - Scaling/offsetting the GCP co-ords by the above
  - I do do this somewhere in one of my utilities I think

Notes on PCI
------------
- Choose Lat/Lon for GCP projection 
- The reference for altitude is nb - for DEM it is sea level and for DGPS GCPs it is ellipsoid (I think)
- WRT to the above, I am not sure if PCI is converting the GCP's to sea level.  We may need to convert them ourselved.  It does say "The EGM96 geoid model will be used to convert these to ellipsoidal heights" in ortho gen doc http://www.pcigeomatics.com/geomatica-help/references/pciFunction_r/python/P_ortho.html 
- The Quickbird level 2A has already had some geo correction applied (what?) and cannot be processed with PCI toutin rigorous model.  We can only use the RPC option.
- RPC adjustment order 1 is recommended for Quickbird - some overfitting can be seen with order 2 using check points 
- Using PCI to assemble the tiles and do pan sharp copies the rpc and satellite info accrosss in meta data (i think) 
- The options->import GCP does not work to import an external file of GCPs.  Use the toolbar button "GCP input" and then select "text/pci" input option.
- Something is not working lekker with all of this: the RMS error comes out round 18 pixels while notes on the web say we should be able to get ce90 < 4m with sub-meter gcp's and a good dem.  The addition of high altitude gcp's and outlier (spatial) gcp's seems to have a worse effect on accuracy than the gcp's we were uncertain of like the braai areas which are actually quite accurate.  Comparing DEM to DGPS heights shows that the DEM is inaccurate by up to ~15m.  This is prob in part due to the DEM tracking top of trees rather than the ground.  Also, it is not clear if, how, when the RPC is applied and what the nature of the GCP adjustment is.  The DEM and or the RPC adjustment or lack thereof seem like the most likely sources of error.  WRT RPC, I did some fiddling to get it to work with pan sharp file and it could perhaps be that the wrong RPC is being applied.  This could be checked by reworking with only PAN.  We could also check doing everything with GDAL / Arcmap rather than PCI.  

Other Orthorect Notes 
-----------
- RPC with DEM on/off in arcmap makes no visible difference at all - even at pixel scale?!  Something does not make sense...  Either the RPC actually does not nothing i.e. is kind of 1 to 1 (surely the DEM would still make a difference though?) or it has aleady been applied by DG or I am doing something wrong.  Doing an Arcmap orthrect with DEM and factor=100 shows absolutely no difference with original ...??? 
- Arc warp using GCP's works pretty good with polyorder =3.  In the sense that al the GCP's then match reasonably well.  The problem is the warp is severe and my guess is badly overfitted.  PCI only goes up to polyorder=2 and recommends 1 for quickbird - this is not enough to fix the gcps.   
- The GCP warping in both PCI and Arcmap does not use height as best I can tell.  It is purely horizontal.  So height above sea level or ellipsoid is NA?  
NNB - DG sent me Level2A "standard" imagery as best I can tell - which is "Projected to a plane using map projection and datum, coarse DEM applied to normalize for topographic relief" i.e. it has been warped in a way that is not reversible or suited to accurate orthorectification.  There is then "ortho-ready standard" aka "Orthoready Standard 2A" imagery which has been "Projected to a plane using map projection and datum, projected to a constant base elevation to allow for orthorectifcation".  I dont think you can rigorous toutin type modelling with this.  For that you need "basic" imagery with no georef.  So we need to go back to digital globe and get this sorted.  
1 0.1508;2 0.1809;3 0.302;4 0.3664
- NB All the above notes are for level 2a, "standard" QB imagery.  This imagery has been coarsely orthorectified using a DEM and cannot be orthorectified further.  Hence the issues we have had. 
- With level 1B, the MS and pan images are no longer overlaid and need co-registration.  It states in QB faq (mendeley) "As a result, proper registration of these bands is dependent on placing the image in an accurate terrain mode".  Co-reg is a little tricky becuase the MS image is too low a resolution to recognise features used for GCP's.  I noticed that in arcmap using the on-fly orthorect (RPC + const elev or DEM) results in the MS and Pan images superimposing exactly.  But we can't use a DEM warp because then we cant orthorectify further (same problem as standard imagery).  And if we use a const elev rectification, technically this can still have offsets between pan and ms in variable terrain.  So we can't use arcmap type RPC projection to co-register the images I don't think.  And we wont find the GCP's in the MS image I don't think.  Perhaps the best option is to orthorectify the pan image, then use this a reference to orthorectify the MS image by choosing other GCP's that can be seen in both images.  I had another idea but I can't remember what now... 
- Dont forget about the ellipsoid to mean sea level conversion for GCP's 
- Some results - the basic level 1b image is a lot more accurate than the std 2a ~ 1.34 pixel RMS error for 15 GCP's (on the fitted ones).  This is excluding a lot of the braai/table gcp's and with some tweaking of other uncertain ones to improve things.  
- To evaluate spatial accuracy of orthorect: exclude dodgy gcp's entirely, then go roughly 60/40 gcp/check point to get an idea from check points.  NB OR do a LOO type approach where each gcp is left out indicidually and the errors on each left one averaged to give an overall figure.  For the final orthorect, use all decent GCP's though.  Similar to classification.   
- X The RMS errors reported in the PCI GUI are a lot smaller than what I see if I look at the GCP's in the final orthorectified image.  I think https://dg-cms-uploads-production.s3.amazonaws.com/uploads/document/file/38/DG_ACCURACY_WP_V3.pdf explains why.  In the GUI, the DEM is not being used, rather the image point is projected to the same height as the GCP and the horizontal error found from there.  This does not consider horizontal displacement caused by DEM innacuracy which is what we see in the final image.  This suggests that a better DEM would help a lot.  Perhapds we could test this by making the GCP's use the DEM height rather than DGPS height and then compare the PCI errors to observed image errors - not quite the same thing though perhaps as it will be the DEM height at the GCP not the projected image point- still should be closer the orthorectified image situation.  
- The above leads to: Perhaps for the next stage, we should get stereo imagery and make our own DEM (this may also allow a check of plant height).  Or perhaps adjust the SUDEM to the GCP's (suspect).   
- It may be worth making some plots of DEM vs GCP height to see if anything systematic is happening there.  And also check SUDEM vs GCP for ellipsoid vs MSL quantitatively.  Because SUDEM errors are big.  
- NB the NGI 2009 and 2015 rectifications look more accurate than mine.  what DEM do they use??
- The NGI 2009 and 2015 imagery rectification sets look similarly accurate in Bavs.   
- NB Rerunning the orthorect with SRTM (ref EGM96) and GCP (ref SAGEOID) but with SRTM offset -4.3m (this is the const offset betw GCP and SRTM) does seem to produce a more accurate ortho image.  
- Then rerunning with SUDEM L3 derived from stereo NGI aerials seems to improve slightly on SRTM and definitely on SUDEM L2.  The SUDEM L3 is more a DTM than a DSM and thererfore should be more appropriate for veg mapping as you are then warping the veg to be something like their orthographic view too.   
- NB DG "basic imagery" can only be ordered in scene increments not km2, I'm not sure if "standard ortho ready" can be orthorect with toutin's model, but it can with RPC's 
https://www.google.co.za/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiP8NOl0bvXAhUFPVAKHQgtAWwQFggmMAA&url=http%3A%2F%2Fwww.mass.gov%2Fanf%2Fdocs%2Fitd%2Fservices%2Fmassgis%2Fbasicimagery-ds-10-14-forweb.pdf&usg=AOvVaw2HfzjpvgBKPQ5Ny3ABEoRi
- NB DG samples of different image types are available here: https://www.digitalglobe.com/resources/product-samples/standard-satellite-imagery, so we can test what is possible with PCI...



Vertical Datum Practicalities
-----------------------------
- The available sw / stds for transforming are flakey
- ArcGIS claims to be able convert vertical datums but when I use the "Project Data" tool, it cannot load the datum grid file.  Then on subsequent runs of the same tool it reports success but makes no change to heights.
- ArcGIS can be used to define the vertical datum in a 3d shapefile (the shapefile produced from Trimble is 3d but ref to ellipsoid wgs84).  Use the "define projection" tool for this.  
- Proj.4 has recent additions for doing vertical datum xformations.  I had to specifically install these with Osgeo4w.  Then I manually downloaded the egm2008.gtx file (the geoid grid) as this was missing and put it with the rest of the gtx files in the osgeo4w tree
- GDAL uses proj.4 and ogr2ogr can be used to convert shapefiles including the vertical datum eg "ogr2ogr -t_srs EPSG:4326+5773 tst.shp BaviiaansPeCorrectedGcpMay2017CombinedZ.shp"
- "testepsg 4326+5773" will give other strings, like proj.4, that can be used for specifying t_srs 
- GDAL does successfully make the conversion - the height values are shifted by -30m though which seems like a lot - to be checked 
- GDAL loses the vertical datum definiton in the target file though so this needs to be manually added with ArcGIS or possibly GDAL itself 
- The SA GEOID is available from NGI but not in gtx format.  gtx is a regular grid while ngi's sageoid2010 is not.  
- For the approx lat lon of my study area, the SAGEOID.dat entry is " -33.666667  24.458333  28.165330".  SO it is ~30m and I guess -ve if you're going from wgs84.  I think the 28.16... is relative to wgs84 more or less (i.e IRTF2005??) - see the pdf with the sageoid.    
- I dont think SAGEOID2010 varies by more than 2m within my study area and maybe less.
- NB The SUDEM is in Hartebeeshoek94 - should we not convert it to WGS84 (vertically???)  Yes it is ref to geoid relative to hartebeeshoek94 - we should convert to rel to wgs84. ??
x - The above does not improve things.  The errors between GCP and DEM we are seeing vary over the study area.  The sa geoid hardly varies at all over this area and it is highly unlikely the wgs or whatever datum will vary either.  i.e. the errors we are seeing are inherent in SUDEM (at least in part).  Fiddling with datums etc is not going to fix that.  
- NB So... I tried comparing GCP's to SUDEM and SRTM and they are closer to SRTM - SUDEM looks to be warped with height somehow.  The SRTM is relative to geoid EGM96.  The SAGEOID2010 and EGM96 differ by ~0.5m in my study area seemingly quite constantly.  
- SUDEM l3 from NGI stereo aerials is a lot more accurate than SUDEM l2.  Compared to SA GEOID 2010 GCP's, I get RMSE 0.8m



Notes on pan-sharpening quickbird 
----------------------------------
- Pan-sharpening should be prob be done before any other steps.  The MS and Pan images lie on top of each other, so it makes sense to do this and then orthorect etc on the single pan-sharpened output.
- PCI's algorithm seems to work well.  
- The choice of weights for Arc's algorithms is important.  These algorithms mostly assume sum(MS bands) = pan.  (Note that for Quickbird, this assumption is only approx valid) Using arbitrary weights violates this assumption.  We could downsample the pan to ms res, then do a ls fit to find the best set of weights that satisfies this assumption.  Sometines the pan band does not include IR, so IR band then needs special treatment.  This is not the case with Quickbird.   


PyQgis and Anaconda
---------------------
- PyQgis and OsGeo4W support can be obtained in Anaconda by making a conda env with same python version as osgeo then editing the environment activation batch file - see "C:\ProgramData\Anaconda3\envs\py27\etc\conda\activate.d\env_vars.bat" to set up all the osgeo env vars.  PyCharcm does not run this batch file though, so PyCharm must be started from an env that already has all these vars set - see "C:\Data\Development\Projects\PhD GeoInformatics\Code\Results\Quickbird Orthorectification\PyCharmOSGeo4W.bat".  
- Note however, that it doesn't seem possible to simply create GUI elements from the python console - you can do it from within qgis.  This requires more investigation.
- In the end I got something to run - it seems you can't instantiate QMainWindow from outside QGIS but other GUI classes are ok.  So maybe we can use a plain qt main window?
- ** OK now I can instantiate QMainWindow - I just need to call QgsApplication.setPrefixPath("C:/OSGeo4W64/apps/qgis") before hand.
- Note that the above is actually using osgeo python i.e. has no access to any of the anaconda libs incl ipython etc 


Num Plots and Plot Size
--------------------------
- A min N for regression is 28 accordinf to AVN.  If this is taken per class then a min N for 3 classes is 100.
- My initial thinking is that with geolocation errors of the order of 2m, we want a plot size >> than this so that we still end up with the majority of our pixels being valid.  5m is too small as one can easily end up with 50% invalid pixels.  10m is a compromise - bigger would be better.
- Also according to AVN, we should work at multispec resolution which means 2.4m for quickbird.  One would like a plot size that has >10 of these pixels to allow us to average out effects like soil mixing.  At 5m we only get 4 pixels, at 10m we get 16 Quickbird pixels and ~60 Worldview pixels.  
- What about somehow mitigating gelocation accuracy issues by having very many small plots?  Very many small plots will better describe the variation in the landscape.  If there are enough plots, the image measurements should describe the corresponding image variation even if they are not located accurately.  But the problem is how do you relate the two together - there is not way to relate specific image values to specific TAGC values when you know your image value has a substantial noise component due to spatial error.  I don't really think this can work.  
- TAGChat = f(image) + im noise   
- f = fit(image to TAGC)
- For very heterogenous veg, the variation between small plots is large so use bigger plots to be spatially representative of variation in habitat and or simply to decrease variation. "Basically, the more similar the observations are, the more efficient is the small plot, and vice versa.
As a rule of thumb, a plot should be large enough to contain enough trees per plot to be representative of the population
It follows that small plots should be employed for dense stands with small trees, and large ones for open stands and large trees"  see "Designing a National Forest Inventory in the context of REDD +"
- 10x10m plots are amongst the smallest used in lit.  
- Stratification only helps if there is real separation between strata - in this case, each stratum can be modelled separately using less plots in ttl than would have been required if all strata were modelled together.  In MP 2005 gt, there is not great separation between strata - which points in part to the need to increase at least DST plot sizes.  But it also means that modelling is best done on all data, not on strata.  

Combining NGI RGB and NIR
--------------------------
- The georef NIR files are shifted/rotated relative to RGB files.  The NIR files also have different NODATA borders so the geotransform cannot simply be copied from RGB to NIR. 
- Also note that the NIR files have slightly different pixel sizes (& orientations ?) and so will need to be resampled to the RGB grid
- We want to make 4 band images in the RGB projection & geotransform so that we can apply orthorect using NGI aerotriangulation
  Somehow we need to either 
  A) Georef the NIR files correctly and then resample to RGB projection and stack on top of RGB file (either adding or removing NODATA boundary as appropriate)
  B) ???
- A) there is a way doc'd here https://gis.stackexchange.com/questions/61512/calculating-image-boundary-footprint-of-satellite-images-using-open-source-too to extract raster boundary into vector.  
     - Make boundary for NIR and RGB files 
     - Find xform between the boundaries 
       Either a) - Apply the xform to the NIR geotransform/(extents) and overwrite the NIR file with this data
       	         - Resample the NIR image to the RGB grid and extent (?)
				 - Stack bands 
		or b) ??? 
    transform = osr.CoordinateTransformation(cs_gt_spatial_ref, osr.SpatialReference(ds.GetProjection()))


Importing shapefile to DGPS for Navigation
-------------------------------------------
How to import a shapefile
- Copy the shapefile(s) to a dir on SD Card
- Put SD Card in DGPS
- Start GNSS
- Select "Data" from tl combobox
- Select "File Manager" from combobox under TL	
- At "Choose File Type:", select "Background Files"
- At "Location:", select "Storage Card"
- Click "Options" and select "Read Background from shape" 
  - Give it a name and select the appropriate folder on the card, 
  - Next to "Include:" check the shapefile you want to include
  - Click "Done" (it should say "...complete")
  - Click "Close"
- Back in file manager, if you change Location: to "Default" you should see the file you just imported
- Now if you go to "Map" you will be able to select the background file you just imported as you did before.  And you will be able to navigate to the points in it. 
  	
	
GEF Site Stratification
-------------------------
- We want a fairly even spread of plots over TAGC for the regression.  There is not an even spread of these by area in the site.  Therefore we stratify into Degraded/ Moderate / Pristine classes and make sure we get enough plots in each class.
- We want to minimise travel times between sites - therefore either cluster, or distr randomly but allow sites to also be visited randomly.  Just generating random points will only save travel time if they are quite dense.  
- We don't want to bias sampling to small clustered areas though.  
- It is perhaps better to generate more than we need in case we have time to do extra.  We then start with 1-100 and if possible carry on with 101-150.  This means we generate points once off and don't have to try and generate new points possibly overallping with old points.  
- We need to make sure we don't overlap with the trial points.  
- It would make sense for Cos to chop and change between Pristine and  Moderate in the field as these sites may be close together.  So we need one global set of points that also says if it is pristine / moderate /...
- Sites should have unique ID's, this will make things easier to keep track of eg we easily know how to geolocate plot allometry.  It will also let Cos know which numbers he should be doing i.e. from the 150 sites, he should be starting with only 1-100.?
- How to split the plots?  Ttl 90, Degraded: 35, Pristine: 30, Moderate: 25, for safety make it times 1.5
	

Funding
--------
- NRF Innovation Award
  - Must be accepted witin 1 month of letter of award
  - Must be "primary" source of funding 
  - Travel grants (once-off) are available for certain funding programmes and are awarded based on successful travel grant applications
  - Must be registered as FT student 
  - The scholarship may not be held concurrently with any other NRF or "Government" funded scholarship/bursary
  - Max 12 hrs work per week at std tariffs
  - The scholarship may be supplemented by other sources to the University’s maximum value at Master’s and Doctoral level.   Where the university does not have a maximum allowable value, the scholarship may be supplemented up to R 250 000 p.a. for Doctoral or in accordance with the South African Receiver of Revenue (SARS) permissible amounts for non-taxable bursaries and scholarships
  - Should the scholarship-holder not complete the degree for which the scholarship was awarded, the funds will have to be returned to the NRF plus interest at the prevailing prime rate charged by the NRF bankers
  - The scholarship-holder will acknowledge the financial assistance of the NRF as follows on the title page of the mini thesis/dissertation as well as in all papers and publications that emanate from the study.
  - The Grantholder will make himself/herself available to participate in NRF reviewing activities during the period of the grant, or anytime thereafter for an additional period not exceeding five (5) years from the expiration or lapse of the grant.
  x - Max 3 years, renewal dependent on availability of funds and progress.  
  
- SANSA
  - R120 000pa, the ttl value of my funding may not exceed the SANSA limit of 120 000
  - Allegedly the first payment is after the proof of registation has been received, second payment in June after progress report.  
  - All publications to be approved by SANSA, SANSA have co-authorship and bear SANSA affiliation
  - Must re-apply each year with proof of progress 
  - No conditions on other work... ?
  - Students are expected to adhere to same working hours as staff members i.e. 8 hr, 5 day week, 

- GEF5
  - SLM = sustainable land management
  - R110,000 for two years, plus a small reserve for the third year if necessary
  - JR "We can certainly reassign some of the money from your proposed bursary to other costs (field data and possibly upgrading the drone imagery to proper multispectral if possible), and the remainder will go towards the other project areas that R3G is undertaking"
  - short (few pages) concept note on your project by the 20th of April 2016 (to my email address: rebeccajoub@gmail.com). This concept note should include an introduction/background to the topic or problem you are investigating, your aim and objectives, a brief overview of the methods you'll use to achieve your objectives, a preliminary budget that includes running costs (field trips/equipment/printing etc). Finally you should describe the contribution your project will make toward improving knowledge and implementation of SLM in communal landscapes of the Eastern Cape (and South Africa for PhDs).


My Notes 
  - NRF does not have a strict req for staff working hours and allows 12 hrs other work.  SANSA does but only "at SANSA" i.e. in Pretoria so not me i.e. I can read it as SANSA has not req on part time work.
  - NRF allows non-gov funding up to 250000pa, SANSA only allows its own funding.
  - Going with NRF, I would lose R10000 but would gain the option to do work on the side and to top up with WWF funding.  
  - Only thing is renewing NRF funding may be harder than renewing SANSA funding...  ?  As I wasn't on the short list to begin with...


- Possible supervisors
  - US - see DSP group - some signal proc and pattern recognition http://dsp.sun.ac.za/~trn/
  - SANSA - Michel Verstraete?


NRF innovation follow up  
SU max: 250000
Administer WWF: it would go via student fees, speak to jean swart jbs@sun.ac.za 


  
-----------------------------------------
If we were to move money from the bursary at this stage, my preference/suggestion would be to opt for the orthorecitified satellite imagery as opposed to the ortho-ready imagery.  This would save time.  Alternatively or perhaps additionally, we could investigate setting up a drone platform with a 4 band multi-spectral camera as James suggested.  This would likely require a higher capacity drone as the DJI Phantom is already close to its limit from what I gather.
-----------------------------------------
	
	
	
	
	
15:30, 17 devon 	
	
Per object prcrossval(dataAll(:, feats),  scalem([], 'variance')*libsvc([], proxm([], 'r', 1)), 10, 1); feats = [8     2    61    29    14];
---------------------------------------

cn =

         0.863636363636364        0.0227272727272727         0.113636363636364
        0.0196078431372549         0.901960784313726        0.0784313725490196
        0.0476190476190476        0.0317460317460317         0.920634920634921


ans =

         0.104589310471663


CRn =

         0.972763347763348        0.0272366522366522
        0.0980392156862745         0.901960784313726


ans =

        0.0626379339614633

Per object prcrossval(dataAll(:, feats),  scalem([], 'variance')*libsvc([], proxm([], 'r', 1)), 10, 1); feats =  [78    14     9    27    11 22];
---------------------------------------
		
cn =

                      0.75        0.0227272727272727         0.227272727272727
        0.0588235294117647          0.92156862745098        0.0196078431372549
        0.0317460317460317        0.0476190476190476         0.920634920634921


ans =

         0.135932150638033


CRn =

          0.96482683982684        0.0351731601731602
        0.0784313725490196          0.92156862745098


ans =

        0.0568022663610899		
		
Per object prcrossval(dataAll, librandomforestc, 10, 1);
---------------------------------------
		
cn =

         0.931818181818182                         0        0.0681818181818182
        0.0196078431372549         0.941176470588235        0.0392156862745098
        0.0476190476190476        0.0476190476190476         0.904761904761905


ans =

        0.0740811476105594


CRn =

         0.976190476190476        0.0238095238095238
        0.0588235294117647         0.941176470588235


ans =

        0.0413165266106443		

		
Per object prcrossval(dataAll(:, feats), qdc, 10, 1); feats = [8     2    61    29    14];
---------------------------------------

		
cn =

         0.909090909090909        0.0227272727272727        0.0681818181818182
                         0          0.96078431372549        0.0392156862745098
        0.0317460317460317        0.0793650793650794         0.888888888888889

ans =

         0.080411962764904


CRn =

         0.948953823953824         0.051046176046176
        0.0392156862745098          0.96078431372549


ans =

        0.0451309311603429
		
		
Per object prcrossval(dataAll(:, feats), knnc([], 3), 10, 1); feats = [ 5     2    62    60    74     1];
---------------------------------------

cn =

         0.977272727272727        0.0227272727272727                         0
                         0         0.941176470588235        0.0588235294117647
        0.0634920634920635        0.0634920634920635         0.873015873015873


ans =

        0.0695116430410548


CRn =

         0.956890331890332        0.0431096681096681
        0.0588235294117647         0.941176470588235


ans =

        0.0509665987607164		


Per-pixel prcrossval(dataAll(:, feats), qdc, 10, 1); feats = [24    18     6     7    37];
----------------------------------------
		
cn =

         0.689506033395456        0.0191590896255718         0.291334876978973
        0.0279071923602902         0.861066685209652         0.111026122430058
          0.11961196119612        0.0962096209620962         0.784178417841784


ans =

          0.22174962118437


CRn =

         0.942315644706166         0.057684355293834
         0.138933314790348         0.861066685209652


ans =

        0.0983088350420912		

		
Per-pixel prcrossval(dataAll(1:10:end, feats), scalem([], 'variance')*knnc([], 9), 10, 1); feats = [31    17    38     7    12]
------------------------------------------

cn =

         0.992611069277108       0.00385918674698795       0.00352974397590361
        0.0524118738404453         0.941790352504638       0.00579777365491651
         0.520438683948156          0.15752741774676         0.322033898305085


ans =

         0.247854893304389


CRn =

         0.919306697753126        0.0806933022468738
        0.0582096474953618         0.941790352504638


ans =

        0.0694514748711178

Per-pixel [err, cerr, nlabOut] = prcrossval(dataAll(1:50:end, feats(1:5)), scalem([], 'variance')*libsvc([], proxm([], 'r', 1)), 10, 1); feats = [ 25    18    29    39     7];
------------------------------------------

cn =

          0.99058158700259       0.00565104779844596       0.00376736519896397
        0.0601851851851852         0.927083333333333        0.0127314814814815
         0.693069306930693         0.173267326732673         0.133663366336634


ans =

         0.316223904442481


CRn =

          0.91054081273444        0.0894591872655596
        0.0729166666666667         0.927083333333333


ans =

        0.0811879269661131
		

Per-pixel [err, cerr, nlabOut] = prcrossval(dataAll(1:50:end, :), librandomforestc, 10, 1); feats = selected implicitly
------------------------------------------

cn =

         0.994584412526489       0.00400282552389922       0.00141276194961149
        0.0810185185185185         0.916666666666667       0.00231481481481481
         0.762376237623762         0.183168316831683        0.0544554455445545


ans =

         0.344764491754097


CRn =

         0.906414428822209        0.0935855711777912
        0.0833333333333333         0.916666666666667


ans =

        0.0884594522555622


Per-pixel prcrossval(subDataAll(:, feats), scalem([], 'variance')*knnc([], 9), 10, 1); feats = [25     2    23     7     6];
------------------------------------------
		
cn =

         0.871487148714872        0.0179017901790179         0.110611061106111
        0.0114011401140114         0.925592559255926         0.063006300630063
        0.0378037803780378        0.0383038303830383         0.923892389238924


ans =

        0.0930093009300931


CRn =

         0.971897189718972        0.0281028102810281
        0.0744074407440744         0.925592559255926


ans =

        0.0512551255125513


Per-pixel pprcrossval(subDataAll(1:5:end, feats),  scalem([], 'variance')*libsvc([], proxm([], 'r', 1)), 10, 1); feats = [25     2    23     7     6];
------------------------------------------		
cn =

                      0.84                     0.013                     0.147
                     0.012                     0.904                     0.084
                     0.084                    0.0735                    0.8425


ans =

         0.137833333333333


CRn =

                   0.95675                   0.04325
                     0.096                     0.904


ans =

                  0.069625
		
		
*AllOcc		
---------------------------------------		
GroenFontein1 0-0, 0.000000
GroenFontein2 3-5, 0.128374
GroenFontein3 10-10, 13.927204
GroenFontein4 20-30, 8.048760
MatjiesVlei1a 5-7, 5.981440
MatjiesVlei1b 20-25, 35.980481
MatjiesVlei2 70-70, 75.231214
MatjiesVlei3 80-90, 79.117971
MatjiesVlei4 65-65, 68.001537
MatjiesVlei5 35-40, 38.976930
MatjiesVlei6 15-20, 12.736947
MatjiesVlei7 15-15, 27.662503
MatjiesVlei8 2-2, 5.170581
RooiBerg1 20-20, 5.765298
RooiBerg2 10-12, 0.566999
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 10.222430
GrootKop2 0-1, 0.119843
GrootKop3 40-45, 35.210979
GrootKop4 75-80, 62.114949
Canopy cover error: 6.721823 (5.685820)

*AllQdc
---------------------------------------		
GroenFontein1 0-0, 0.000000
GroenFontein2 3-5, 0.146204
GroenFontein3 10-10, 13.226000
GroenFontein4 20-30, 8.048760
MatjiesVlei1a 5-7, 5.993137
MatjiesVlei1b 20-25, 34.913532
MatjiesVlei2 70-70, 70.756040
MatjiesVlei3 80-90, 77.221610
MatjiesVlei4 65-65, 54.585614
MatjiesVlei5 35-40, 30.887539
MatjiesVlei6 15-20, 11.356834
MatjiesVlei7 15-15, 26.201567
MatjiesVlei8 2-2, 5.315550
RooiBerg1 20-20, 5.790235
RooiBerg2 10-12, 0.588531
RooiBerg3 0-0, 0.016167
GrootKop1 20-25, 9.764143
GrootKop2 0-1, 0.130939
GrootKop3 40-45, 35.129045
GrootKop4 75-80, 60.028540
Canopy cover error: 7.262886 (5.764738)

*All_Knnc_clfr
---------------------------------------		
GroenFontein1 0-0, 0.071676
GroenFontein2 3-5, 1.212424
GroenFontein3 10-10, 14.895973
GroenFontein4 20-30, 14.915121
MatjiesVlei1a 5-7, 5.061218
MatjiesVlei1b 20-25, 30.241201
MatjiesVlei2 70-70, 71.098646
MatjiesVlei3 80-90, 76.207277
MatjiesVlei4 65-65, 67.924709
MatjiesVlei5 35-40, 39.826656
MatjiesVlei6 15-20, 15.680080
MatjiesVlei7 15-15, 29.419860
MatjiesVlei8 2-2, 6.282014
RooiBerg1 20-20, 4.683058
RooiBerg2 10-12, 1.083758
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 9.180337
GrootKop2 0-1, 0.157571
GrootKop3 40-45, 31.872184
GrootKop4 75-80, 60.146639
Canopy cover error: 6.453053 (5.657077)

*All_Svc_clfr
---------------------------------------		
GroenFontein1 0.000000 0.078076
GroenFontein2 4.000000 2.250116
GroenFontein3 10.000000 14.988236
GroenFontein4 25.000000 15.835703
MatjiesVlei1a 6.000000 4.527022
MatjiesVlei1b 22.500000 34.124697
MatjiesVlei2 70.000000 76.846609
MatjiesVlei3 85.000000 72.767365
MatjiesVlei4 65.000000 67.953520
MatjiesVlei5 37.500000 36.219569
MatjiesVlei6 17.500000 11.855670
MatjiesVlei7 15.000000 26.011010
MatjiesVlei8 2.000000 9.384363
RooiBerg1 20.000000 3.585856
RooiBerg2 11.000000 0.222493
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 10.975539
GrootKop2 0.500000 0.208615
GrootKop3 42.500000 35.470436
GrootKop4 77.500000 58.409605
Canopy cover error: 7.077926 (5.591997)

*All_RandomForest_clfr
---------------------------------------		
GroenFontein1 0.000000 0.002560
GroenFontein2 4.000000 1.618942
GroenFontein3 10.000000 11.362273
GroenFontein4 25.000000 11.711382
MatjiesVlei1a 6.000000 4.679092
MatjiesVlei1b 22.500000 33.211974
MatjiesVlei2 70.000000 74.112865
MatjiesVlei3 85.000000 79.073870
MatjiesVlei4 65.000000 68.039950
MatjiesVlei5 37.500000 32.009177
MatjiesVlei6 17.500000 8.846026
MatjiesVlei7 15.000000 27.514292
MatjiesVlei8 2.000000 4.271770
RooiBerg1 20.000000 4.663109
RooiBerg2 11.000000 0.775138
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 8.225816
GrootKop2 0.500000 0.088772
GrootKop3 42.500000 32.329646
GrootKop4 77.500000 59.551225
Canopy cover error: 6.972174 (5.738826)


All_RandomForest_clfr_3class
------------------------------------
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.185430
GroenFontein3 10.000000 10.840984
GroenFontein4 25.000000 9.816728
MatjiesVlei1a 6.000000 6.071122
MatjiesVlei1b 22.500000 31.748078
MatjiesVlei2 70.000000 73.106350
MatjiesVlei3 85.000000 77.949283
MatjiesVlei4 65.000000 77.364832
MatjiesVlei5 37.500000 50.516209
MatjiesVlei6 17.500000 20.236116
MatjiesVlei7 15.000000 39.191192
MatjiesVlei8 2.000000 6.378660
RooiBerg1 20.000000 4.194305
RooiBerg2 11.000000 0.480873
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 8.427229
GrootKop2 0.500000 0.068799
GrootKop3 42.500000 32.671036
GrootKop4 77.500000 66.164748
Canopy cover error Mean(abs) Std(abs): 7.899756 (6.729910)
Canopy cover error Median Mad: 0.000000 (8.037516)

All_Svc_clfr_3class
---------------------------------------
GroenFontein1 0.000000 0.001280
GroenFontein2 4.000000 1.019862
GroenFontein3 10.000000 9.890668
GroenFontein4 25.000000 12.781172
MatjiesVlei1a 6.000000 5.377057
MatjiesVlei1b 22.500000 33.684769
MatjiesVlei2 70.000000 76.544832
MatjiesVlei3 85.000000 77.750827
MatjiesVlei4 65.000000 73.417843
MatjiesVlei5 37.500000 39.333815
MatjiesVlei6 17.500000 12.096774
MatjiesVlei7 15.000000 27.853059
MatjiesVlei8 2.000000 4.223446
RooiBerg1 20.000000 3.920004
RooiBerg2 11.000000 0.617240
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 10.050207
GrootKop2 0.500000 0.099869
GrootKop3 42.500000 35.251946
GrootKop4 77.500000 66.971755
Canopy cover error Mean(abs) Std(abs): 6.436583 (5.175548)
Canopy cover error Median Mad: 0.511537 (6.536410)

All_Mogc_clfr_Occ
---------------------------------------
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.003566
GroenFontein3 10.000000 5.752641
GroenFontein4 25.000000 4.752118
MatjiesVlei1a 6.000000 3.365047
MatjiesVlei1b 22.500000 24.630866
MatjiesVlei2 70.000000 66.547139
MatjiesVlei3 85.000000 71.422271
MatjiesVlei4 65.000000 70.450399
MatjiesVlei5 37.500000 33.929558
MatjiesVlei6 17.500000 6.875624
MatjiesVlei7 15.000000 16.525513
MatjiesVlei8 2.000000 2.280854
RooiBerg1 20.000000 2.448756
RooiBerg2 11.000000 0.215316
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 5.674587
GrootKop2 0.500000 0.029961
GrootKop3 42.500000 26.416769
GrootKop4 77.500000 52.170062
Canopy cover error Mean(abs) Std(abs): 7.939211 (7.802877)
Canopy cover error Median Mad: 3.783438 (7.502092)

All_Knnc_clfr
---------------------------------------
GroenFontein1 0.000000 0.071676
GroenFontein2 4.000000 1.158934
GroenFontein3 10.000000 14.812935
GroenFontein4 25.000000 14.771544
MatjiesVlei1a 6.000000 5.072916
MatjiesVlei1b 22.500000 30.142597
MatjiesVlei2 70.000000 70.990361
MatjiesVlei3 85.000000 76.207277
MatjiesVlei4 65.000000 67.963123
MatjiesVlei5 37.500000 39.775672
MatjiesVlei6 17.500000 15.638510
MatjiesVlei7 15.000000 29.229303
MatjiesVlei8 2.000000 6.291679
RooiBerg1 20.000000 4.693033
RooiBerg2 11.000000 1.083758
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 9.165742
GrootKop2 0.500000 0.157571
GrootKop3 42.500000 31.988256
GrootKop4 77.500000 60.077748
Canopy cover error Mean(abs) Std(abs): 6.438103 (5.653795)
Canopy cover error Median Mad: 0.634756 (6.667076)


All_Qdc_clfr_3class (+affine weighting)
---------------------------------------
GrootKop4 75-80, 60.249975
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.000000
GroenFontein3 10.000000 12.335655
GroenFontein4 25.000000 3.797753
MatjiesVlei1a 6.000000 5.720190
MatjiesVlei1b 22.500000 38.195287
MatjiesVlei2 70.000000 80.601069
MatjiesVlei3 85.000000 82.006615
MatjiesVlei4 65.000000 79.650437
MatjiesVlei5 37.500000 56.345329
MatjiesVlei6 17.500000 21.724310
MatjiesVlei7 15.000000 44.431505
MatjiesVlei8 2.000000 7.142167
RooiBerg1 20.000000 3.271657
RooiBerg2 11.000000 0.086126
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 9.480997
GrootKop2 0.500000 0.098759
GrootKop3 42.500000 34.876417
GrootKop4 77.500000 60.249975
Canopy cover error Mean(abs) Std(abs): 9.766863 (8.383854)
Canopy cover error Median Mad: 0.139905 (9.832006)

<PerArea>_Svc_clfr_3class
---------------------------------------
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.777378
GroenFontein3 10.000000 17.479356
GroenFontein4 25.000000 10.630331
MatjiesVlei1a 6.000000 1.505108
MatjiesVlei1b 22.500000 13.607403
MatjiesVlei2 70.000000 55.202102
MatjiesVlei3 85.000000 65.931643
MatjiesVlei4 65.000000 49.697494
MatjiesVlei5 37.500000 17.716786
MatjiesVlei6 17.500000 3.067842
MatjiesVlei7 15.000000 7.103536
MatjiesVlei8 2.000000 0.792500
RooiBerg1 20.000000 7.241534
RooiBerg2 11.000000 1.385201
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 5.937299
GrootKop2 0.500000 0.058812
GrootKop3 42.500000 23.344258
GrootKop4 77.500000 43.647279
Canopy cover error Mean(abs) Std(abs): 11.166643 (8.587411)
Canopy cover error Median Mad: 11.186633 (7.589636)

<PerArea>_RandomForest_clfr_3class
---------------------------------------
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.534893
GroenFontein3 10.000000 14.817549
GroenFontein4 25.000000 10.461417
MatjiesVlei1a 6.000000 1.411526
MatjiesVlei1b 22.500000 14.080198
MatjiesVlei2 70.000000 57.035840
MatjiesVlei3 85.000000 67.717751
MatjiesVlei4 65.000000 54.134255
MatjiesVlei5 37.500000 21.107193
MatjiesVlei6 17.500000 4.223479
MatjiesVlei7 15.000000 9.813678
MatjiesVlei8 2.000000 0.879482
RooiBerg1 20.000000 7.924792
RooiBerg2 11.000000 1.148353
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 4.863098
GrootKop2 0.500000 0.017754
GrootKop3 42.500000 19.349993
GrootKop4 77.500000 38.185218
Canopy cover error Mean(abs) Std(abs): 10.771431 (9.491674)
Canopy cover error Median Mad: 10.358696 (7.460020)

RTrees_Small
-----------------------------------------
GroenFontein1 0-0, 0.000000
GroenFontein2 3-5, 0.000000
GroenFontein3 10-10, 8.432901
GroenFontein4 20-30, 4.746488
MatjiesVlei1a 5-7, 5.821571
MatjiesVlei1b 20-25, 33.667071
MatjiesVlei2 70-70, 75.044823
MatjiesVlei3 80-90, 78.103638
MatjiesVlei4 65-65, 83.453376
MatjiesVlei5 35-40, 53.762162
MatjiesVlei6 15-20, 18.431992
MatjiesVlei7 15-15, 33.548592
MatjiesVlei8 2-2, 4.764666
RooiBerg1 20-20, 4.169368
RooiBerg2 10-12, 0.337329
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 9.075252
GrootKop2 0-1, 0.115404
GrootKop3 40-45, 34.111703
GrootKop4 75-80, 62.159236
Canopy cover error Mean(abs) Std(abs): 8.504990 (7.209759)
Canopy cover error Median Mad: 0.281513 (8.567459)

RTrees
-----------------------------------------
GroenFontein1 0-0, 0.000000
GroenFontein2 3-5, 0.167600
GroenFontein3 10-10, 6.795221
GroenFontein4 20-30, 6.556685
MatjiesVlei1a 5-7, 4.230679
MatjiesVlei1b 20-25, 25.536003
MatjiesVlei2 70-70, 67.954840
MatjiesVlei3 80-90, 73.472988
MatjiesVlei4 65-65, 64.928455
MatjiesVlei5 35-40, 31.448358
MatjiesVlei6 15-20, 10.683405
MatjiesVlei7 15-15, 25.195850
MatjiesVlei8 2-2, 3.305306
RooiBerg1 20-20, 3.117052
RooiBerg2 10-12, 0.294265
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 6.596999
GrootKop2 0-1, 0.036619
GrootKop3 40-45, 27.836952
GrootKop4 75-80, 58.173408
Canopy cover error Mean(abs) Std(abs): 7.312182 (6.786976)
Canopy cover error Median Mad: 3.518590 (6.759370)

opencv SVM, trained in opencv but with matlab scaling
---------------------------------
GroenFontein1 0-0, 0.001280
GroenFontein2 3-5, 0.634740
GroenFontein3 10-10, 5.664991
GroenFontein4 20-30, 6.103432
MatjiesVlei1a 5-7, 2.768463
MatjiesVlei1b 20-25, 21.058354
MatjiesVlei2 70-70, 65.467843
MatjiesVlei3 80-90, 69.283352
MatjiesVlei4 65-65, 62.172285
MatjiesVlei5 35-40, 29.400518
MatjiesVlei6 15-20, 7.532424
MatjiesVlei7 15-15, 16.292611
MatjiesVlei8 2-2, 1.768629
RooiBerg1 20-20, 1.316643
RooiBerg2 10-12, 0.236848
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 5.371008
GrootKop2 0-1, 0.019974
GrootKop3 40-45, 23.132596
GrootKop4 75-80, 49.335695
Canopy cover error Mean(abs) Std(abs): 8.426305 (8.425416)
Canopy cover error Median Mad: 4.433583 (7.231268)

subData = gendat(dataAll, [2000 2000 2000]);
opencvdtreec([], 12, {'Priors', [0.25 0.5 0.25], 'MaxDepth', 12, 'Use1seRule', false, ...
        'UseSurrogates', false, 'CVFolds', 5, 'TruncatePrunedTree', true, 'MinSampleCount', min(classsizes(subData))/100})
		feats = [ 9    15    20    23     7     6] 
------------------------------------------
GroenFontein1 0.000000 0.133113
GroenFontein2 4.000000 0.684663
GroenFontein3 10.000000 10.827144
GroenFontein4 25.000000 20.517440
MatjiesVlei1a 6.000000 9.217812
MatjiesVlei1b 22.500000 34.860437
MatjiesVlei2 70.000000 67.021107
MatjiesVlei3 85.000000 73.583241
MatjiesVlei4 65.000000 69.547681
MatjiesVlei5 37.500000 40.026342
MatjiesVlei6 17.500000 18.116063
MatjiesVlei7 15.000000 30.340885
MatjiesVlei8 2.000000 8.311588
RooiBerg1 20.000000 6.902399
RooiBerg2 11.000000 1.055049
RooiBerg3 0.000000 0.016167
GrootKop1 22.500000 9.521864
GrootKop2 0.500000 0.533745
GrootKop3 42.500000 35.286085
GrootKop4 77.500000 70.534396
Canopy cover error Mean(abs) Std(abs): 5.916237 (5.006131)
Canopy cover error Median Mad: -0.024956 (6.048550)

as above but saved from matlab to yaml and then run in c++
---------------------------------------
GroenFontein1 0-0, 0.005120
GroenFontein2 3-5, 3.130906
GroenFontein3 10-10, 9.134105
GroenFontein4 20-30, 12.327919
MatjiesVlei1a 5-7, 7.053732
MatjiesVlei1b 20-25, 37.072714
MatjiesVlei2 70-70, 78.820585
MatjiesVlei3 80-90, 79.647189
MatjiesVlei4 65-65, 80.889273
MatjiesVlei5 35-40, 49.594256
MatjiesVlei6 15-20, 21.416694
MatjiesVlei7 15-15, 41.996612
MatjiesVlei8 2-2, 6.620276
RooiBerg1 20-20, 4.887537
RooiBerg2 10-12, 0.681834
RooiBerg3 0-0, 0.008083
GrootKop1 20-25, 12.210287
GrootKop2 0-1, 0.215273
GrootKop3 40-45, 36.337567
GrootKop4 75-80, 65.574255
Canopy cover error Mean(abs) Std(abs): 8.091524 (7.100094)
Canopy cover error Median Mad: 0.139803 (8.231446)

opencv dtree trained in c++, otherwise as above
----------------------------------------------
GroenFontein1 0-0, 0.133113
GroenFontein2 3-5, 0.677531
GroenFontein3 10-10, 10.656456
GroenFontein4 20-30, 20.303482
MatjiesVlei1a 5-7, 9.252905
MatjiesVlei1b 20-25, 34.868022
MatjiesVlei2 70-70, 67.264303
MatjiesVlei3 80-90, 73.561191
MatjiesVlei4 65-65, 70.143090
MatjiesVlei5 35-40, 40.302502
MatjiesVlei6 15-20, 18.124376
MatjiesVlei7 15-15, 29.769214
MatjiesVlei8 2-2, 8.388905
RooiBerg1 20-20, 6.877462
RooiBerg2 10-12, 1.119644
RooiBerg3 0-0, 0.016167
GrootKop1 20-25, 9.702843
GrootKop2 0-1, 0.521538
GrootKop3 40-45, 35.299741
GrootKop4 75-80, 70.337565
Canopy cover error Mean(abs) Std(abs): 5.926626 (4.938059)
Canopy cover error Median Mad: -0.018853 (6.057526)

opencv dtree trained in c++ with morph close(2x2), open(2x2), otherwise as above
----------------------------------------------
GroenFontein1 0-0, 0.088315
GroenFontein2 3-5, 0.584816
GroenFontein3 10-10, 9.120266
GroenFontein4 20-30, 19.039441
MatjiesVlei1a 5-7, 7.849177
MatjiesVlei1b 20-25, 33.495146
MatjiesVlei2 70-70, 67.606909
MatjiesVlei3 80-90, 73.274531
MatjiesVlei4 65-65, 73.081725
MatjiesVlei5 35-40, 39.380550
MatjiesVlei6 15-20, 14.599268
MatjiesVlei7 15-15, 27.662503
MatjiesVlei8 2-2, 6.349667
RooiBerg1 20-20, 6.488454
RooiBerg2 10-12, 1.004809
RooiBerg3 0-0, 0.000000
GrootKop1 20-25, 8.786269
GrootKop2 0-1, 0.296278
GrootKop3 40-45, 35.586508
GrootKop4 75-80, 71.759669
Canopy cover error Mean(abs) Std(abs): 5.862993 (4.789522)
Canopy cover error Median Mad: 1.636413 (5.754648)



scalem([], 'variance')*opencvsvc feats = [ 9    15    20    23     7     6] 
------------------------------------------
GroenFontein1 0.000000 0.001280
GroenFontein2 4.000000 0.328068
GroenFontein3 10.000000 8.100752
GroenFontein4 25.000000 7.195743
MatjiesVlei1a 6.000000 4.624503
MatjiesVlei1b 22.500000 27.495449
MatjiesVlei2 70.000000 69.772602
MatjiesVlei3 85.000000 72.524807
MatjiesVlei4 65.000000 67.329300
MatjiesVlei5 37.500000 36.440498
MatjiesVlei6 17.500000 12.944795
MatjiesVlei7 15.000000 28.403557
MatjiesVlei8 2.000000 3.440611
RooiBerg1 20.000000 3.476136
RooiBerg2 11.000000 0.566999
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 6.792574
GrootKop2 0.500000 0.069908
GrootKop3 42.500000 26.614775
GrootKop4 77.500000 55.275071
Canopy cover error Mean(abs) Std(abs): 7.322148 (7.357215)
Canopy cover error Median Mad: 1.637373 (7.531799)

Canopy cover error Mean(abs) Std(abs): 5.854323 (4.654542)
Canopy cover error Median Mad: 2.206197 (5.519555)


Xcalib spot valid
	Band	Mean	Std	Median	Mad
-------------------------------
	1	5.9204	5.1721	4.7600	2.6200
	2	3.7571	3.7984	2.7400	1.6800
	3	2.9448	2.7158	2.3200	1.2600
	All	3.9172	4.0214	3.0600	1.8400
-------------------------------


----------------------------------------------------------------------------------------------
    cs = classsizes(dataAll);
    cs(1) = cs(2);
    subData = gendat(dataAll, cs);
	
	w = subData(:, feats)*opencvrtreec([], [], {'Priors', [1 2 1]/4, ...
      'MaxNumOfTreesInTheForest', 5, 'NActiveVars', 4, 'CalcVarImportance', false, 'MaxDepth', 10, 'ForestAccuracy', 0.025})
	feats = 9    15    20    23     7     6

GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.224655
GroenFontein3 10.000000 6.970522
GroenFontein4 25.000000 9.369106
MatjiesVlei1a 6.000000 4.484130
MatjiesVlei1b 22.500000 28.324737
MatjiesVlei2 70.000000 71.901017
MatjiesVlei3 85.000000 76.317530
MatjiesVlei4 65.000000 70.805724
MatjiesVlei5 37.500000 35.794706
MatjiesVlei6 17.500000 10.034919
MatjiesVlei7 15.000000 30.182088
MatjiesVlei8 2.000000 2.967044
RooiBerg1 20.000000 3.555932
RooiBerg2 11.000000 0.509582
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 6.877226
GrootKop2 0.500000 0.024412
GrootKop3 42.500000 29.885293
GrootKop4 77.500000 62.872749
Canopy cover error Mean(abs) Std(abs): 7.087992 (6.068908)
Canopy cover error Median Mad: 2.367386 (6.861821)


----------------------------------------------------------------------------------------------
    subData = gendat(dataAll, [2000 2000 2000]);
    subData = changelablist(subData, 'Default');
    subData = setprior(subData, 0);
	
	w = subData(:, feats)*(scalem([], 'variance')*knnc([], 5));
	feats = 9    15    20    23     7     6
	
GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.046357
GroenFontein3 10.000000 6.924390
GroenFontein4 25.000000 7.398440
MatjiesVlei1a 6.000000 4.008422
MatjiesVlei1b 22.500000 30.663430
MatjiesVlei2 70.000000 74.103989
MatjiesVlei3 85.000000 78.213892
MatjiesVlei4 65.000000 63.190243
MatjiesVlei5 37.500000 28.232145
MatjiesVlei6 17.500000 8.264051
MatjiesVlei7 15.000000 29.081093
MatjiesVlei8 2.000000 2.735092
RooiBerg1 20.000000 1.974964
RooiBerg2 11.000000 0.150721
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 8.506042
GrootKop2 0.500000 0.057702
GrootKop3 42.500000 31.401065
GrootKop4 77.500000 60.712528
Canopy cover error Mean(abs) Std(abs): 7.600132 (6.198883)
Canopy cover error Median Mad: 3.514626 (6.962021)

----------------------------------------------------------------------------------------------
    subData = gendat(dataAll, [2000 2000 2000]);
    subData = changelablist(subData, 'Default');
    subData = setprior(subData, 0);
	
w = subData(:, feats)*(scalem([], 'variance')*opencvsvc([], [],...
    {'SVMType', 'C_SVC', 'KernelType', 'RBF', 'Gamma', 5, 'C', 1, 'ClassWeights', double([1; 3; 1])}))

GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.338765
GroenFontein3 10.000000 7.644047
GroenFontein4 25.000000 5.624842
MatjiesVlei1a 6.000000 3.513218
MatjiesVlei1b 22.500000 25.005057
MatjiesVlei2 70.000000 69.066089
MatjiesVlei3 85.000000 70.893054
MatjiesVlei4 65.000000 69.384423
MatjiesVlei5 37.500000 36.975825
MatjiesVlei6 17.500000 8.912537
MatjiesVlei7 15.000000 19.637942
MatjiesVlei8 2.000000 2.300184
RooiBerg1 20.000000 3.002344
RooiBerg2 11.000000 0.351683
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 5.619125
GrootKop2 0.500000 0.012206
GrootKop3 42.500000 25.590605
GrootKop4 77.500000 54.797756
Canopy cover error Mean(abs) Std(abs): 7.424275 (7.636352)
Canopy cover error Median Mad: 2.421367 (7.627593)

----------------------------------------------------------------------------------------------
    cs = classsizes(dataAll);
    cs(1) = cs(2);
    subData = gendat(dataAll, cs);
		
w = subData(:, feats)*(scalem([], 'variance')*opencvsvc([], [],...
    {'SVMType', 'C_SVC', 'KernelType', 'RBF', 'Gamma', 5, 'C', 1, 'ClassWeights', double([1; 1; 1])})) //unequal weights cause issues with unequal class sizes...

GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.559855
GroenFontein3 10.000000 6.670665
GroenFontein4 25.000000 6.055573
MatjiesVlei1a 6.000000 3.025813
MatjiesVlei1b 22.500000 21.258091
MatjiesVlei2 70.000000 66.742407
MatjiesVlei3 85.000000 70.253583
MatjiesVlei4 65.000000 64.025737
MatjiesVlei5 37.500000 32.255598
MatjiesVlei6 17.500000 10.192883
MatjiesVlei7 15.000000 19.521491
MatjiesVlei8 2.000000 2.106891
RooiBerg1 20.000000 1.725600
RooiBerg2 11.000000 0.150721
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 4.781365
GrootKop2 0.500000 0.005548
GrootKop3 42.500000 23.357913
GrootKop4 77.500000 50.260801
Canopy cover error Mean(abs) Std(abs): 7.990311 (8.334824)
Canopy cover error Median Mad: 3.384740 (7.422213)	

----------------------------------------------------------------------------------------------
    cs = classsizes(dataAll);
    cs(1) = cs(2);
    subData = gendat(dataAll, cs);
		
w = subData(:, feats)*qdc

	GroenFontein1 0.000000 0.000000
GroenFontein2 4.000000 0.000000
GroenFontein3 10.000000 6.094017
GroenFontein4 25.000000 1.672250
MatjiesVlei1a 6.000000 3.181783
MatjiesVlei1b 22.500000 28.319680
MatjiesVlei2 70.000000 70.961958
MatjiesVlei3 85.000000 77.331863
MatjiesVlei4 65.000000 63.622395
MatjiesVlei5 37.500000 28.856694
MatjiesVlei6 17.500000 5.038244
MatjiesVlei7 15.000000 16.641965
MatjiesVlei8 2.000000 1.961921
RooiBerg1 20.000000 2.089671
RooiBerg2 11.000000 0.000000
RooiBerg3 0.000000 0.000000
GrootKop1 22.500000 5.607449
GrootKop2 0.500000 0.031070
GrootKop3 42.500000 27.645774
GrootKop4 77.500000 49.788407
Canopy cover error Mean(abs) Std(abs): 8.075103 (8.345712)
Canopy cover error Median Mad: 3.952992 (7.537496)

-------------------------------------------------------------------------------------------
[err, cerr, nlabOut] = prcrossval(d(:, feats), opencvdtreec([], 12, {'Priors', p./sum(p), 'MaxDepth', 12, 'Use1seRule', false, ...
        'UseSurrogates', false, 'CVFolds', 5, 'TruncatePrunedTree', true, 'MinSampleCount', min(classsizes(subData))/100}), 10);

    ''                      'Background'            'Spekboom'             'Tree'                 'Total'    'Cons Acc'         
    'Background'            [             24867]    [              302]    [             2091]    [27260]    [0.912215700660308]
    'Spekboom'              [               323]    [            25757]    [             1180]    [27260]    [0.944864269992663]
    'Tree'                  [               277]    [              196]    [             2884]    [ 3357]    [0.859100387250521]
    'Total'                 [             25467]    [            26255]    [             6155]    [57877]    [                1]
    'Prod Acc'              [ 0.976440098951584]    [0.981032184345839]    [0.468562144597888]    [    1]    [              NaN]
    'Kappa'                 [ 0.868240874572752]                     []                     []         []                     []
    'Overall acc'           [0.0754876721322806]                     []                     []         []                     []
    'Overall =prior acc'    [0.0946065473655024]                     []                     []         []                     []

    ''                      'Background'            'Spekboom'             'Total'      'Cons Acc'         
    'Background'            [           15059.5]    [              249]    [15308.5]    [0.983734526570206]
    'Spekboom'              [              1503]    [            25757]    [  27260]    [0.944864269992663]
    'Total'                 [           16562.5]    [            26006]    [42568.5]    [                1]
    'Prod Acc'              [ 0.909252830188679]    [0.990425286472353]    [      1]    [              NaN]
    'Kappa'                 [ 0.912218182024224]                     []           []                     []
    'Overall acc'           [0.0411571936995666]                     []           []                     []
    'Overall =prior acc'    [0.0357006017185653]                     []           []                     []
-------------------------------------------------------------------------------------------
[err, cerr, nlabOut, stds, r] = prcrossval(d(:, feats), scalem([], 'variance')*knnc([], 5), 10);

    ''                      'Background'          'Spekboom'            'Tree'               'Total'    'Cons Acc'        
    'Background'            [           26463]    [             331]    [            466]    [27260]    [97.0763022743947]
    'Spekboom'              [             187]    [           26939]    [            134]    [27260]    [98.8224504768892]
    'Tree'                  [             553]    [             362]    [           2442]    [ 3357]    [72.7435210008937]
    'Total'                 [           27203]    [           27632]    [           3042]    [57877]    [             100]
    'Prod Acc'              [ 97.279711796493]    [97.4920382165605]    [80.276134122288]    [  100]    [             NaN]
    'Kappa'                 [0.93621627695305]                    []                   []         []                    []
    'Overall acc'           [3.51262159407019]                    []                   []         []                    []
    'Overall =prior acc'    [10.4525754159408]                    []                   []         []                    []

    ''                      'Background'           'Spekboom'            'Total'    'Cons Acc'        
    'Background'            [            29924]    [             693]    [30617]    [97.7365515889865]
    'Spekboom'              [              321]    [           26939]    [27260]    [98.8224504768892]
    'Total'                 [            30245]    [           27632]    [57877]    [             100]
    'Prod Acc'              [ 98.9386675483551]    [97.4920382165605]    [  100]    [             NaN]
    'Kappa'                 [0.964868175942042]                    []         []                    []
    'Overall acc'           [  1.7519912918776]                    []         []                    []
    'Overall =prior acc'    [ 1.72049896706215]                    []         []                    []

-------------------------------------------------------------------------------------------
[err, cerr, nlabOut, stds, r] = prcrossval(d(:, feats), opencvrtreec([], [], {'Priors', [1 2 1]/4, ...
     'MaxNumOfTreesInTheForest', 50, 'NActiveVars', 4, 'CalcVarImportance', false, 'MaxDepth', 10, 'ForestAccuracy', 0.025}), 10);	
	
    ''                      'Background'           'Spekboom'           'Tree'                'Total'    'Cons Acc'        
    'Background'            [            24441]    [            387]    [            2432]    [27260]    [89.6588407923698]
    'Spekboom'              [              133]    [          26431]    [             696]    [27260]    [96.9589141599413]
    'Tree'                  [              185]    [            288]    [            2884]    [ 3357]    [85.9100387250521]
    'Total'                 [            24759]    [          27106]    [            6012]    [57877]    [             100]
    'Prod Acc'              [ 98.7156185629468]    [97.509776433262]    [47.9707252162342]    [  100]    [             NaN]
    'Kappa'                 [0.875498245391381]                   []                    []         []                    []
    'Overall acc'           [ 7.12027230160512]                   []                    []         []                    []
    'Overall =prior acc'    [  9.1574021075456]                   []                    []         []                    []

    ''                      'Background'           'Spekboom'           'Total'    'Cons Acc'        
    'Background'            [            29942]    [            675]    [30617]    [ 97.795342456805]
    'Spekboom'              [              829]    [          26431]    [27260]    [96.9589141599413]
    'Total'                 [            30771]    [          27106]    [57877]    [             100]
    'Prod Acc'              [ 97.3059049104676]    [97.509776433262]    [  100]    [             NaN]
    'Kappa'                 [0.947836119378413]                   []         []                    []
    'Overall acc'           [ 2.59861430274547]                   []         []                    []
    'Overall =prior acc'    [ 2.62287169162683]                   []         []                    []
	
-------------------------------------------------------------------------------------------
[err, cerr, nlabOut, stds, r] = prcrossval(d(:, feats), scalem([], 'variance')*opencvsvc([], [], ...
    {'SVMType', 'C_SVC', 'KernelType', 'RBF', 'Gamma', 25, 'C', .1, 'ClassWeights', double([1; 1; 1])}), 10);
	
    ''                      'Background'           'Spekboom'            'Tree'                'Total'    'Cons Acc'        
    'Background'            [            25744]    [            1027]    [             489]    [27260]    [94.4387380777696]
    'Spekboom'              [              206]    [           26902]    [             152]    [27260]    [98.6867204695525]
    'Tree'                  [              545]    [             290]    [            2522]    [ 3357]    [75.1266011319631]
    'Total'                 [            26495]    [           28219]    [            3163]    [57877]    [             100]
    'Prod Acc'              [ 97.1655029250802]    [95.3329317126759]    [79.7344293392349]    [  100]    [             NaN]
    'Kappa'                 [0.915140373337755]                    []                    []         []                    []
    'Overall acc'           [ 4.68061578865525]                    []                    []         []                    []
    'Overall =prior acc'    [ 10.5826467735716]                    []                    []         []                    []

    ''                      'Background'           'Spekboom'            'Total'    'Cons Acc'        
    'Background'            [            29300]    [            1317]    [30617]    [95.6984681712774]
    'Spekboom'              [              358]    [           26902]    [27260]    [98.6867204695525]
    'Total'                 [            29658]    [           28219]    [57877]    [             100]
    'Prod Acc'              [ 98.7929057927035]    [95.3329317126759]    [  100]    [             NaN]
    'Kappa'                 [0.942035038707631]                    []         []                    []
    'Overall acc'           [ 2.89406845551774]                    []         []                    []
    'Overall =prior acc'    [ 2.80740567958507]                    []         []                    []

-------------------------------------------------------------------------------------------
d = subData;
p = [1 1 1];
d = setprior(d, p./sum(p))
[err, cerr, nlabOut, stds, r] = prcrossval(d(:, feats), qdc, 10);


    ''                      'Background'           'Spekboom'            'Tree'                'Total'    'Cons Acc'        
    'Background'            [            21374]    [             213]    [            5673]    [27260]    [78.4079236977256]
    'Spekboom'              [              537]    [           22734]    [            3989]    [27260]    [83.3969185619956]
    'Tree'                  [              156]    [             196]    [            3005]    [ 3357]    [89.5144474232946]
    'Total'                 [            22067]    [           23143]    [           12667]    [57877]    [             100]
    'Prod Acc'              [ 96.8595640549236]    [98.2327269584756]    [23.7230599194758]    [  100]    [             NaN]
    'Kappa'                 [0.699735779277092]                    []                    []         []                    []
    'Overall acc'           [ 18.5980614060853]                    []                    []         []                    []
    'Overall =prior acc'    [ 16.2269034389947]                    []                    []         []                    []

    ''                      'Background'           'Spekboom'            'Total'    'Cons Acc'        
    'Background'            [            30208]    [             409]    [30617]    [  98.66414083679]
    'Spekboom'              [             4526]    [           22734]    [27260]    [83.3969185619956]
    'Total'                 [            34734]    [           23143]    [57877]    [             100]
    'Prod Acc'              [ 86.9695399320551]    [98.2327269584756]    [  100]    [             NaN]
    'Kappa'                 [0.827461714956717]                    []         []                    []
    'Overall acc'           [  8.5267031808836]                    []         []                    []
    'Overall =prior acc'    [  8.9694703006072]                    []         []                    []
	
	
Cluster 7, Accuracy 0.312
	rN, 	nirN, 	NDVI, 	RVI, 	tc2, 	pc2, 	rc1, 	MeanRVI, 	MedianRVI, 	MeanNDVI, 	MedianNDVI, 
Cluster 1, Accuracy 0.383
	R, 	G, 	B, 	NIR, 	tc1, 	pc1, 	MeanPc1, 	MedianPc1, 
Cluster 2, Accuracy 0.396
	EntropyPc1, 
Cluster 8, Accuracy 0.449
	gN, 	MeanGn, 	MedianGn, 
Cluster 9, Accuracy 0.454
	bN, 
Cluster 4, Accuracy 0.462
	rc2, 	rc4, 
Cluster 5, Accuracy 0.456
tc4, 	rc3, 

Cluster 6, Accuracy 0.512
	pc4, 
Cluster 11, Accuracy 0.523
	EntropyRVI, 	StdRVI, 	EntropyNDVI, 	StdNDVI, 
Cluster 12, Accuracy 0.560
	EntropyGn, 	StdGn, 
Cluster 10, Accuracy 0.566
	StdPc1, 
Cluster 3, Accuracy 0.571
	tc3, 	pc3, 
Cluster 14, Accuracy 0.588
	SkewnessRVI, 	SkewnessNDVI, 
Cluster 15, Accuracy 0.636
	SkewnessGn, 
Cluster 17, Accuracy 0.644
	SkewnessPc1, 
Cluster 18, Accuracy 0.647
	KurtosisGn, 
Cluster 13, Accuracy 0.652
	KurtosisRVI, 	KurtosisNDVI, 
Cluster 16, Accuracy 0.661
	KurtosisPc1, 	
	
	
Cluster 7, Accuracy 0.014
	rN, 	nirN, 	NDVI, 	RVI, 	tc2, 	pc2, 	rc1, 	MeanRVI, 	MedianRVI, 	MeanNDVI, 	MedianNDVI, 
Cluster 2, Accuracy 0.057
	EntropyPc1, 
Cluster 1, Accuracy 0.146
	R, 	G, 	B, 	NIR, 	tc1, 	pc1, 	MeanPc1, 	MedianPc1, 
Cluster 9, Accuracy 0.007
	bN, 
Cluster 5, Accuracy 0.018
	tc4, 	rc3, 
Cluster 8, Accuracy 0.010
	gN, 	MeanGn, 	MedianGn, 
Cluster 4, Accuracy 0.022
	rc2, 	rc4, 


Num.	Importance (%)	Features
1	68.27	rN, nirN, NDVI, RVI, tc2, pc2, rc1, MeanRVI, MedianRVI, MeanNDVI, MedianNDVI
2	61.38	R, G, B, NIR, tc1, pc1, MeanPc1, MedianPc1
3	60.41	EntropyPc1
4	55.23	gN, MeanGn, MedianGn
5	54.52	bN
6	53.57	rc2, rc4
7	50.57	tc4, rc3 
8	49.34	pc4 
9	47.93	EntropyRVI, StdRVI, EntropyNDVI, StdNDVI
10	43.96	StdPc1
11	43.62	EntropyGn, StdGn
12	42.65	tc3, pc3
13	41.29	SkewnessRVI, SkewnessNDVI
14	35.27	SkewnessGn
15	35.19	KurtosisRVI, KurtosisNDVI
16	35.03	SkewnessPc1
17	34.86	KurtosisGn
18	33.86	KurtosisPc1

